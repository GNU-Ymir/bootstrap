mod second;

import ymirc::utils::_;
import ymirc::lexing::_;

import std::conv, std::io;

pub aka __testTokenizer_1_expect__ = (str #{[( -> false, ]
[x -> false, ]
[, -> false, ]
[  -> true, ]
[y -> false, ]
[) -> false, ]
[  -> true, ]
[=> -> false, ]
[  -> true, ]
[# -> false, #]
Toggeling skip
[  -> false, ]
[this -> false, ]
[  -> false, ]
[is -> false, ]
[  -> false, ]
[a -> false, ]
[  -> false, ]
[comment -> false, ]
[  -> false, ]
[# -> false, #]
Toggeling skip
[  -> true, ]
[x -> false, ]
[  -> true, ]
[+ -> false, ]
[  -> true, ]
[y -> false, ]
[  -> true, ]
[* -> false, ]
[  -> true, ]
[2 -> false, ]
[  -> true, ]
[# -> false, #]
Toggeling skip
[  -> false, ]
[second -> false, ]
[  -> false, ]
[comment -> false, ]
[  -> false, ]
[# -> false, #]
Toggeling skip
[  -> true, ]
}).to![c8]();


pub aka __testLexer_1__expect__ = (str#{['def' 5 9 50 -> /**
         * Some comments
         */]
['main' 5 13 50 -> ]
['(' 5 18 50 -> ]
[')' 5 19 50 -> ]
['{' 5 21 50 -> ]
['let' 6 13 72 -> ]
['x' 6 17 72 -> ]
['=' 6 19 72 -> ]
['12' 6 21 72 -> ]
['+' 6 24 72 -> ]
['32' 6 26 72 -> ]
[';' 6 28 72 -> ]
['let' 7 13 101 -> ]
['z' 7 17 101 -> ]
['=' 7 19 101 -> ]
['84' 7 21 101 -> ]
[';' 7 23 101 -> ]
['let' 8 13 125 -> ]
['w' 8 17 125 -> ]
['=' 8 19 125 -> ]
['"' 8 21 125 -> ]
['str' 8 22 125 -> ]
[' ' 8 25 125 -> ]
['in' 8 26 125 -> ]
[' ' 8 28 125 -> ]
['multiple' 8 29 125 -> ]
[' ' 8 37 125 -> ]
['words' 8 38 125 -> ]
['"' 8 43 125 -> ]
[';' 8 44 125 -> ]
['}' 9 9 170 -> ]
}).to![c8]();
    


__test {
    logging::setRelativeTime ();
    logging::info (" testTokenizer_1 start"s8);
    
    let dmut tzer = Tokenizer::new (tokens-> ["("s8, ")"s8, "=>"s8, ","s8, "="s8, "+"s8, "*"s8]);
    // set a skip token
    tzer:.insert (" "s8, isSkip-> true); 
    
    // insert a comment token
    tzer:.insert ("#"s8, isComment-> "#"s8);
    
    let mut cursor = 0us;
    let content =  "(x, y) => # this is a comment # x + y * 2 # second comment # "s8;
    
    let mut skiping = true;
    let dmut stream = Formatter::new ();
    
    loop {
        let (len, isSkip, isComment) = tzer.next (content [cursor .. $]);
        if len != 0u64 {
            stream:.write (format ("[% -> %, %]\n"s8, content [cursor .. cursor + len], isSkip, isComment));
        } else break {}
        
        if (content [cursor .. cursor + len] == "#"s8) {
            skiping = !skiping;
            tzer:.insert (" "s8, isSkip-> skiping);
            stream:.write ("Toggeling skip\n"s8);
        }
        
        cursor += len;
    }
    assert (stream [] == __testTokenizer_1_expect__);
}

__test {                        // 
    logging::setRelativeTime ();
    logging::info (" testLexer_1 start"s8);
    let txt = (str #{
        /**
         * Some comments
         */
        def main () {
            let x = 12 + 32;
            let z = 84;
            let w = "str in multiple words";
        }
    }).to![c8]();

    let dmut lex = Lexer::new ("main.yr"s8, txt, tokens-> Tokens::members, comments-> [const ("/*"s8, "*/"s8), ("//"s8, "\n"s8)]);
    let dmut stream = Formatter::new ();
    let mut skipping = true;
    loop {
        let (word, comm) = lex:.next ();
        if (word.isEof ()) break {}
        else {
            stream:.write (format ("['%' % % % -> %]\n"s8, word.str (), word.line (), word.col (), word.lineSeek (), comm));
            if (word.str () == Tokens::DQUOTE) {
                if (skipping) {
                    lex:.setSkips (["\n"s8, "\r"s8]);
                } else {
                    lex:.setSkips (["\n"s8, "\r"s8, " "s8, "\t"s8]);
                }
                skipping = !skipping;
            }
        }
    }    
    assert (stream [] == __testLexer_1__expect__);
}
