mod second;

import ymirc::utils::_;
import ymirc::lexing::_;

import std::conv, std::io;

pub aka __testTokenizer_1_expect__ = str8#{[( -> false, ]
[x -> false, ]
[, -> false, ]
[  -> true, ]
[y -> false, ]
[) -> false, ]
[  -> true, ]
[=> -> false, ]
[  -> true, ]
[# -> false, #]
Toggeling skip
[  -> false, ]
[this -> false, ]
[  -> false, ]
[is -> false, ]
[  -> false, ]
[a -> false, ]
[  -> false, ]
[comment -> false, ]
[  -> false, ]
[# -> false, #]
Toggeling skip
[  -> true, ]
[x -> false, ]
[  -> true, ]
[+ -> false, ]
[  -> true, ]
[y -> false, ]
[  -> true, ]
[* -> false, ]
[  -> true, ]
[2 -> false, ]
[  -> true, ]
[# -> false, #]
Toggeling skip
[  -> false, ]
[second -> false, ]
[  -> false, ]
[comment -> false, ]
[  -> false, ]
[# -> false, #]
Toggeling skip
[  -> true, ]
};


pub aka __testLexer_1__expect__ = str8#{['def' 5 9 50 -> /**
         * Some comments
         */]
['main' 5 13 50 -> ]
['(' 5 18 50 -> ]
[')' 5 19 50 -> ]
['{' 5 21 50 -> ]
['let' 6 13 72 -> ]
['x' 6 17 72 -> ]
['=' 6 19 72 -> ]
['12' 6 21 72 -> ]
['+' 6 24 72 -> ]
['32' 6 26 72 -> ]
[';' 6 28 72 -> ]
['let' 7 13 101 -> ]
['z' 7 17 101 -> ]
['=' 7 19 101 -> ]
['84' 7 21 101 -> ]
[';' 7 23 101 -> ]
['let' 8 13 125 -> ]
['w' 8 17 125 -> ]
['=' 8 19 125 -> ]
['"' 8 21 125 -> ]
['"' 8 43 125 -> str in multiple words]
[';' 8 44 125 -> ]
['}' 9 9 170 -> ]
};
   


__test {
    logging::setRelativeTime ();
    logging::info (" testTokenizer_1 start"s8);
    
    let dmut tzer = Tokenizer::new (tokens-> ["("s8, ")"s8, "=>"s8, ","s8, "="s8, "+"s8, "*"s8]);
    // set a skip token
    tzer:.insert (" "s8, isSkip-> true); 
    
    // insert a comment token
    tzer:.insert ("#"s8, isComment-> "#"s8);
    
    let mut cursor = 0us;
    let content =  "(x, y) => # this is a comment # x + y * 2 # second comment # "s8;
    
    let mut skiping = true;
    let dmut stream = Formatter::new ();
    
    loop {
        let (len, isSkip, isComment, _) = tzer:.next (content [cursor .. $]);
        if len != 0u64 {
            stream:.write (format ("[% -> %, %]\n"s8, content [cursor .. cursor + len], isSkip, isComment));
        } else break {}
        
        if (content [cursor .. cursor + len] == "#"s8) {
            skiping = !skiping;
            tzer:.insert (" "s8, isSkip-> skiping);
            stream:.write ("Toggeling skip\n"s8);
        }
        
        cursor += len;
    }
    assert (stream [] == __testTokenizer_1_expect__);
    logging::info (" testTokenizer_1 end"s8);
}

__test {                        // 
    logging::setRelativeTime ();
    logging::info (" testLexer_1 start"s8);
    let txt = (str8 #{
        /**
         * Some comments
         */
        def main () {
            let x = 12 + 32;
            let z = 84;
            let w = "str in multiple words";
        }
    });

    let dmut lex = Lexer::new ("main.yr"s8, txt, tokens-> Tokens::members, comments-> [const ("/*"s8, "*/"s8, ["/*"s8]), ("//"s8, "\n"s8, [])]);
    let dmut stream = Formatter::new ();
    loop {
        let (word, comm) = lex:.next ();
        if (word.isEof ()) break {}
        else {
            stream:.write (format ("['%' % % % -> %]\n"s8, word.str (), word.line (), word.col (), word.lineSeek (), comm));
            if (word.str () == Tokens::DQUOTE) {
                let (res, end) = lex:.getString (closing-> Tokens::DQUOTE);
                if (end.isEof ()) assert (false);
                stream:.write (format ("['%' % % % -> %]\n"s8, end.str (), end.line (), end.col (), end.lineSeek (), res));       
            }
        }
    }
    
    assert (stream [] == __testLexer_1__expect__);
    logging::info (" testLexer_1 end"s8);
}
