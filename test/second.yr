in second;

use ymirc::utils::_;
use ymirc::lexing::_;

use std::{conv, io, syntax::_};

pub def __testTokenizer_1_expect__ = str#{[( -> false, ]
[x -> false, ]
[, -> false, ]
[  -> true, ]
[y -> false, ]
[) -> false, ]
[  -> true, ]
[=> -> false, ]
[  -> true, ]
[# -> false, #]
Toggeling skip
[  -> false, ]
[this -> false, ]
[  -> false, ]
[is -> false, ]
[  -> false, ]
[a -> false, ]
[  -> false, ]
[comment -> false, ]
[  -> false, ]
[# -> false, #]
Toggeling skip
[  -> true, ]
[x -> false, ]
[  -> true, ]
[+ -> false, ]
[  -> true, ]
[y -> false, ]
[  -> true, ]
[* -> false, ]
[  -> true, ]
[2 -> false, ]
[  -> true, ]
[# -> false, #]
Toggeling skip
[  -> false, ]
[second -> false, ]
[  -> false, ]
[comment -> false, ]
[  -> false, ]
[# -> false, #]
Toggeling skip
[  -> true, ]
};


pub def __testLexer_1__expect__ = str#{['fn' 5 9 50 -> /**
         * Some comments
         */]
['main' 5 12 50 -> ]
['(' 5 17 50 -> ]
[')' 5 18 50 -> ]
['{' 5 20 50 -> ]
['let' 6 13 71 -> ]
['x' 6 17 71 -> ]
['=' 6 19 71 -> ]
['12' 6 21 71 -> ]
['+' 6 24 71 -> ]
['32' 6 26 71 -> ]
[';' 6 28 71 -> ]
['let' 7 13 100 -> ]
['z' 7 17 100 -> ]
['=' 7 19 100 -> ]
['84' 7 21 100 -> ]
[';' 7 23 100 -> ]
['let' 8 13 124 -> ]
['w' 8 17 124 -> ]
['=' 8 19 124 -> ]
['"' 8 21 124 -> ]
['"' 8 43 124 -> str in multiple words]
[';' 8 44 124 -> ]
['}' 9 9 169 -> ]
};
   


__test {
    logging::setRelativeTime ();
    logging::info (" testTokenizer_1 start");
    
    let dmut tzer = Tokenizer!{c8} (tokens-> copy ["(", ")", "=>", ",", "=", "+", "*"]);
    // set a skip token
    tzer:.insert (" ", isSkip-> true);
    
    // insert a comment token
    tzer:.insert ("#", isComment-> "#");
    
    let mut cursor = 0us;
    let content =  "(x, y) => # this is a comment # x + y * 2 # second comment # ";
    
    let mut skiping = true;
    let dmut stream = copy Formatter ();
    
    loop {
        let (len, isSkip, isComment) = tzer.next (content [cursor .. $]);
        if len != 0 {
            stream:.write (format ("[% -> %, %]\n", content [cursor .. cursor + len], isSkip, isComment));
        } else break;
        
        if (content [cursor .. cursor + len] == "#") {
            skiping = !skiping;
            tzer:.insert (" ", isSkip-> skiping);
            stream:.write ("Toggeling skip\n");
        }
        
        cursor += len;
    }
    assert (stream [] == __testTokenizer_1_expect__);
    logging::success (" testTokenizer_1 end");
}

__test {                        // 
    logging::setRelativeTime ();
    logging::info (" testLexer_1 start");
    let txt = (str#{
        /**
         * Some comments
         */
        fn main () {
            let x = 12 + 32;
            let z = 84;
            let w = "str in multiple words";
        }
    });

    let dmut lex = copy Lexer ("main.yr", txt,
                               tokens-> tokens::TokenList,
                               skips-> tokens::SkipList,
                               comments-> tokens::CommentList);
    let dmut stream = copy Formatter ();
    loop {
        let (word, comm) = lex:.next ();
        if (word.isEof ()) break;
        else {
            stream:.write (format ("['%' % % % -> %]\n", word.str, word.line, word.col, word.getLineSeek (), comm));
            if (word.str == Tokens::DQUOTE) {
                let (res, end) = lex:.getString (closing-> Tokens::DQUOTE);
                if (end.isEof ()) assert (false);
                stream:.write (format ("['%' % % % -> %]\n", end.str, end.line, end.col, end.getLineSeek (), res));
            }
        }
    }

    assert (stream [] == __testLexer_1__expect__);
    logging::success (" testLexer_1 end");
}
