in lexing;

use ymirc::utils::_;
use ymirc::lexing::_;
use ymirc::errors::message;

use std::{conv, io, syntax::_};
use std::fs::{file, path};


fn unescape (txt: [c8])-> [c8] {
    let mut res = "";
    for c in txt {
        if c == '\n' { res ~= "\\n"; }
        else if c == '\t' { res ~= "\\t"; }
        else if c == '\r' { res ~= "\\r"; }
        else res ~= [c];
    }

    res
}

__test {
    logging::setRelativeTime ();
    logging::info (" testTokenizer_1 start");
    
    let dmut tzer = Tokenizer (tokens-> copy ["(", ")", "=>", ",", "=", "+", "*", "'", "-"]);

    // set the skip token
    tzer:.insert (" ", isSkip-> true);
    tzer:.insert ("\n", isSkip-> true);    
    tzer:.insert ("\r", isSkip-> true);    
    tzer:.insert ("\t", isSkip-> true);
    
    // insert the comment tokens
    tzer:.insert ("#", isComment-> true);

    // insert the string tokens
    tzer:.insert ("'", isString-> true);

    for i in 1 ... 1 {
        let txt = {
            let dmut f = File::open (Path (format ("test_resources/tokenizer/test%.txt", i)));
            f:.readAll ()
        };

        let output = {
            let dmut f = File::open (Path (format ("test_resources/tokenizer/test%.out", i)));
            f:.readAll ()
        };        
        
        
        let mut cursor = 0us;    
        let dmut stream = copy Formatter ();
        
        loop {
            let (len, isToken, isSkip, isComment, isString) = tzer.next (txt [cursor .. $]);
            if len == 0
                break;

            let word = unescape (txt [cursor .. cursor + len]);
            stream:.write ("'", word, "'");
            if isToken {
                stream:.write (" @tok");
            }
            
            if isSkip {
                stream:.write (" @sk");
            }

            if isString {
                stream:.write (" @str");
            }

            if isComment {
                stream:.write (" @comm");
            }
            
            stream:.write ("\n");                    
            cursor += len;
        }
        
        utils::compareResultWithString (stream, output);
    }

    
    logging::success (" testTokenizer_1 end");
}

__test {                        // 
    logging::setRelativeTime ();
    logging::info (" testLexer_1 start");

    let mut i = 1;
    loop {
        let p = Path (format ("test_resources/lexing/test%.yr", i));
        let outP = Path (format ("test_resources/lexing/test%.out", i));
        if !std::fs::sys::isFile (p)
            break;
                      
        let txt = {
            let dmut f = File::open (p);
            f:.readAll ()
        };
        
        let dmut stream = copy Formatter ();
        {
            let dmut lex = copy SrcLexer ("main.yr", txt);            
            loop {
                let (word, comm) = lex:.next ();
                stream:.write (word);
                match word {
                    EofWord ()     => { stream:.write (" @eof\n"); break; }
                    StringWord ()  => { stream:.write (" @str\n"); }                    
                    TokenWord ()   => { stream:.write (" @tok\n"); }
                    KeyWord ()     => { stream:.write (" @key\n"); }
                    NameWord ()    => { stream:.write (" @name\n"); }
                    NumericWord () => { stream:.write (" @num\n"); }
                    FloatWord ()   => { stream:.write (" @fl\n"); }
                    LocWord ()     => { stream:.write (" @loc\n"); }
                }
                    
                stream:.write ("COMM : [", comm, "]\n");                
            }

            let output = {
                let dmut f = File::open (outP);
                f:.readAll ()
            };        
            
            utils::compareResultWithString (stream, output);
        } catch {
            err : &ErrorMsg => {
                utils::compareErrorWithFile (err?, outP);                
            }
            e : &AssertError => {
                throw e;
            }
            fs : &std::fs::errors::FsError => {
                throw fs;
            }
        }                                   

        i += 1;
    }
    
    logging::success (" testLexer_1 end");
}
