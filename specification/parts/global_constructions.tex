\section{Modules}%
\label{sec:modules}

A module is a first-level symbol that can contain other types of symbols. Any
other type of symbol is necessarily contained within a module.

\subsection{File module}

A source file declares a module symbol. Its name can be specified explicitly
with the keyword \token{in} as the first line of code. The purpose of this line
is for documentation purposes only, any comment above this line is considered
part of the documentation of the module symbol. The documentation syntax is
described in Chapter~\ref{chap:documentation}. The name of the module must
be the same as the file it is described in. For example, the file
\textit{foo.yr} should start with the line \token{in foo;}. This line is
optional.


\begin{lstlisting}[style=coloredverbatim]
/**
 * Documentation of the /foo/ module.
 * @Authors: John Doe
 * @Licence: GPLv3
 */
in foo;
\end{lstlisting}

A module can enclose other modules with the keyword \token{mod}. The name of
the enclosed module follows the keyword, and must be the name of the file being
enclosed. It can be a sibling file, or a child file (in the subdirectory with
the same name as the parent module). If both files exist (child and sibling),
the compiler will generate an error. Depending on whether they are child files
(in a directory whose name is the name of the enclosing module) or sibling
files, enclosed modules are either child or sibling. For example, assuming the
file hierarchy shown in Figure~\ref{fig:file_hierarchy}, the module located in
the file \token{./foo/bar.yr} and enclosed by the module \token{./foo.yr} will
be named \token{foo::bar} whereas the module located in \token{./baz.yr}, even
if enclosed by the module \token{foo}, will be named \token{baz}. A complete
example is given below for the file hierarchy shown in
figure~\ref{fig:file_hierarchy}.

\input{images/file_hierarchy}

\noindent 1) Root directory :

\vspace{-5pt}%
\begin{minipage}[t][][t]{0.47\linewidth}
\begin{lstlisting}[caption=\textit{./foo.yr}, style=coloredverbatim]
in foo;

mod baz;
pub mod bar;
mod qux;

\end{lstlisting}
\end{minipage}\hspace{5pt}%
\begin{minipage}[t][][t]{0.47\linewidth}
\begin{lstlisting}[caption=\textit{./baz.yr}, style=coloredverbatim]
in baz;

pub fn pubFuncInBaz () {}
fn prvFuncInBaz () {}
\end{lstlisting}
\end{minipage}


\noindent 2) Subdirectory \textit{foo/}:

\vspace{-5pt}%
\begin{minipage}[t][][t]{0.47\linewidth}
\begin{lstlisting}[caption=\textit{./foo/bar.yr}, style=coloredverbatim]
in bar;

pub fn pubFuncInBar () {}
fn prvFuncInBar () {}
\end{lstlisting}
\end{minipage}\hspace{5pt}%
\begin{minipage}[t][][t]{0.47\linewidth}
\begin{lstlisting}[caption=\textit{./foo/qux.yr}, style=coloredverbatim]
in qux;

pub fn pubFuncInQux () {}
fn prvFuncInQux () {}
\end{lstlisting}
\end{minipage}

\subsection{Describing a package}

Only one file has to be passed to the compiler. For example, considering the
file topology described in the previous example, only the \token{./foo.yr} file
is passed to the compiler. All inner modules declared in the \token{foo} module
will be reached and validated by the compiler. A file hierarchy of source files
is called a \emph{package}, and always starts with a root file.

This is the main reason for sibling modules, as only one file is the entry point
of a package, whereas sometimes multiple root modules would be needed. In this
example, the module \token{baz} is a sibling to the module \token{foo}, as it is
described within the source code in \textit{foo.yr}. The following bash command
line is used to compile the package. The \token{-fdump-ymir} option is used to
dump files representing what the compiler generated at each stage, and
\token{-nostdinc} to not automatically include the standard library and runtime.

\begin{lstlisting}[style=bashVerb, escapechar=@+]
@+\textcolor{teal!80}{alice@dev}@+:~$ gyc foo.yr -fdump-ymir -nostdinc
\end{lstlisting}

The file \token{foo.yr.ydump-decls.1} shows the symbol tree declared during the
declaration phase (before validation, so without template symbols -
\token{foo.yr.ydump-decls.2} contains all declared symbols after validation, so
including the templates).

\begin{lstlisting}[style=bashVerb, escapechar=@+]
baz
    baz::prvFuncInBaz
    pub baz::pubFuncInBaz
pub foo
    pub foo::bar
        foo::bar::prvFuncInBar
        pub foo::bar::pubFuncInBar
    foo::qux
        foo::qux::prvFunctionInQux
        pub foo::qux::pubFunctionInQux
\end{lstlisting}

\subsection{Local module}

A module can be declared directly inside another module without using another
file. In this case, the module is considered a child module, and therefore the
result is identical to a file module located in a subdirectory. For example, the
\token{foo} module described above could have been written as follows. The
generated symbol tree is exactly the same.

%\begin{minipage}{\linewidth}
\begin{lstlisting}[caption=\textit{./foo.yr}, style=coloredverbatim]
in foo;

mod baz;

pub mod bar {
  pub fn pubFuncInBar () {}
  fn prvFuncInBar () {}
}

mod qux {
  pub fn pubFuncInQux () {}
  fn prvFuncInQux () {}
}
\end{lstlisting}
%\end{minipage}

\subsection{Protection}
\label{sec:symbol_protection}

The keywords \token{pub} (for public) and \token{prv} (for private) are used
to define the protection of a symbol. By default, a symbol is private. A private
symbol is accessible only by the module that declares it and by the other child
symbols declared in the same module. In other words, a module has access to all
the symbols it has declared and all the symbols declared by its parents. But it
does not have access to the private symbols declared by its child modules, or
those declared by siblings or cousins.

To clarify the situation, let's look at the symbol lookup algorithm. This
algorithm always starts with the symbol requesting access, then looks at its
siblings, then at the parent symbol and its siblings, and then at the
grandparents and their siblings. For example, if the symbol
\token{foo::bar::pubFuncInBar} makes a symbol lookup request, then three levels
of symbols are visible as described in the figure~\ref{fig:symbol_privacy}. In
addition to these levels, public symbols declared within visible symbols are
also visible, recursively.

\input{images/symbol_privacy}

As a result, the symbol \token{foo::bar::pubFuncInBar} has access to the symbol
\token{foo::qux::pubFuncInQux}, even if the symbol \token{qux} is declared
private by the parent module \token{foo}. On the other hand, the symbol
\token{foo::bar::pubFuncInBar} does not have access to
\token{foo::qux::prvFuncInQux}, nor does the symbol \token{baz} have access to
the module \token{foo::qux}.

\subsection{Package importation}

As we have seen, a package is compiled by passing the path to its root file to
the compiler. But a package may depend on other packages, which need to be
imported in order to use the symbols they describe. This is done by using the
compiler's \token{-I} option to import an external package and declare its
symbols in the symbol table. All symbols imported by this method are not
validated by the compiler (except for template symbols which are generated on
invocation - see Chapter~\ref{chap:templates}). So they have to be validated
manually and linked during symbol linking.

In the following example, let's consider two packages, the package \token{foo},
located in the directory \token{/home/alice/mypackage/foo.yr}, which declares a
sub-module \token{bar}, and a second package \token{qux}, located in the path
\token{/home/alice/external/qux.yr}, and which declares a module \token{baz}.

\begin{lstlisting}[caption=\textit{/home/alice/mypackage/foo.yr}, style=coloredverbatim]
in foo;

mod bar {
  pub fn tryAccessToBaz () {
    qux::baz::funcInBaz ();
  }
}
\end{lstlisting}

\begin{lstlisting}[caption=\textit{/home/alice/external/qux.yr}, style=coloredverbatim]
in qux;

pub mod baz {
  pub fn funcInBaz () {
    std::io::println ("Success !");
  }
}
\end{lstlisting}

In order for the module \token{foo::bar} to access the module
\token{qux::baz}, the following command line must be written. It will declare
the symbol \token{qux} as a sibling module of the root module \token{foo} and
thus with the same privacy protection as described above. Therefore, the module
\token{qux::baz} must be declared public to be accessible by the module
\token{foo} and its children.

\begin{lstlisting}[style=bashVerb, escapechar=@+]
@+\textcolor{teal!80}{alice@dev}@+:~$ gyc foo.yr -I ../external/qux.yr
\end{lstlisting}

Because the \token{qux} package is not validated, the above command will result
in a linking error stating that the symbol \token{qux::baz::funcInBaz} was not
found. This is a linking error, not a validation error. To correct this error,
the \token{qux} package must first be validated and then linked when compiling
the \token{foo} package. In the following bash command lines, the option
\textit{-c} is used to create an object file (\textit{qux.o}), that is used
afterwards during the linking in the compilation of the package \textit{foo.yr}.

\begin{lstlisting}[style=bashVerb, escapechar=@+]
@+\textcolor{teal!80}{alice@dev}@+:~$ cd /home/alice/external
@+\textcolor{teal!80}{alice@dev}@+:~/external$ gyc -c qux.yr -o qux.o
@+\textcolor{teal!80}{alice@dev}@+:~/mypackage$ cd ../mypackage
@+\textcolor{teal!80}{alice@dev}@+:~/mypackage$ gyc foo.yr -I ../external/qux.yr   \
                                    ../external/qux.o
\end{lstlisting}

\notebox {
  The symbol \token{qux::baz::funcInBaz} has access to the symbol
  \token{std::io::println} because the compiler includes the standard library
  package by default. This import follows the same rules as any other package
  import, and this package could be imported manually using the \token{-I}
  option, followed by the path to the standard library installation, and
  \token{-nostdinc} to disable automatic import. This can be useful for testing
  new or custom versions of the standard library. For more information on the
  standard library and runtime, see Chapter~\ref{chap:std_and_core_runtime}.
}

\subsection {Using a module}

As you may have noticed, the full path of symbols has to be written to access
them, for example in \token{foo::bar:tryAccessToBaz} the access to the symbol
\token {qux::baz::funcInBaz} was in full letter. This can be cumbersome, so the
construction \token{use} was introduced. This construction is followed by the
ymir path of a module, in order to describe that a symbol name written in the
current context can come from this module. For example, let's say you need to
use the \token{println} often, then the \token{use std::io;} construction can
be useful. The use construction is enclosed in the symbol that makes the
statement and its children.

%\begin{minipage}{\linewidth}
\begin{lstlisting}[caption=\textit{./foo.yr}, style=coloredverbatim]
in foo;

mod bar {
  use qux::baz;
  use std::io;

  pub fn tryAccessToBaz () {
    funcInBaz ();
    println ("io without full name");
  }
}


fn funcInFoo () {
  std::io::println ("Need full name, foo did not use std::io");
}
\end{lstlisting}
%\end{minipage}

The declaration dump file \token{foo.yr.ydump-decls.1} contains the list of
modules used within a given symbol. The core modules are the modules that are
automatically imported and used in every module when the \token{-nostdinc}
option is not used. They contain symbols used by the runtime and referenced by
the compiler to perform high-level operations (such as deep copies of slices,
exception throwing, etc.). More information about the runtime and the standard
library is presented in Chapter~\ref{chap:std_and_core_runtime}.

\begin{lstlisting}[caption=\textit{foo.yr.ydump-decls.1}, style=bashVerb, escapechar=@+]
  pub foo - use {core, core::array, core::range,
                 core::exception, core::typeinfo,
                 core::duplication, core::math}
  foo::bar - use {core, core::array, core::range,
                  std::io, qux::baz,
                  core::exception, core::typeinfo,
                  core::duplication, core::math}
      pub foo::bar::tryAccessToBaz
  foo::funcInFoo
\end{lstlisting}

The path described in a \token{use} statement can be more complex, describing a
tree of modules to use. For example, you may want to use the modules
\token{std::io}, \token{std::fs::path}, and \token{std::fs::file}. This can
be done in a single line.

\begin{lstlisting}[style=coloredverbatim]
in foo;

use std::{io, fs::{path, file}};
\end{lstlisting}

\subsubsection*{Use statement locality}

As explained above, \token{use} statements are enclosed by the symbol that
makes them and by its children. However, in addition to this, use statements are
local to a file, meaning that child modules declared in files other than their
parent module don't have access to the use statements of their parent modules.
This is enforced to avoid cluttering up child modules with use statements they
may not need or even want, and to make use statements clearer since they're
always in the same file as the file they affect. As a result, there is a slight
difference between a child module declared locally in the same file, and a child
module declared in a subdirectory file.
\smallskip

1) When using a single file:

\begin{lstlisting}[caption=\textit{./foo.yr}, style=coloredverbatim]
in foo;
use std::io;

mod bar {
  fn inBar () {
    println("In bar."); // ok, with the use statement from /foo/.
  }
}
\end{lstlisting}

2) When using two separate files:

\hspace{-0.03\linewidth}%
\begin{minipage}[t][][t]{0.3\linewidth}%
\begin{lstlisting}[caption=\textit{./foo.yr}, style=coloredverbatim]
in foo;
use std::io;

mod bar;
\end{lstlisting}
\end{minipage}%
\hspace{0.02\linewidth}%
\begin{minipage}[t][][t]{0.65\linewidth}
\begin{lstlisting}[caption=\textit{./foo/bar.yr}, style=coloredverbatim, escapechar=@]
in bar;

fn inBar () {
  @\hb{println}@("In bar."); // error, parent use statement is hidden
}
\end{lstlisting}
\end{minipage}%

\vfill%
\pagebreak

\section{Functions}%
\label{sec:functions}

A function is a piece of code that can be called to perform a defined behavior.
A function is declared using the keyword \token{fn} followed by the name of the
function to be described. A function is enclosed in a module like any other
global symbol.

\subsection{Parameters}
\label{sec:function_parameters}

The parameters of a function are declared in parentheses after the function
identifier. Parameters serve as the input of the function, allowing to pass data
to the function when calling it. A parameter declaration follows the syntax
\token{ident : T}, where \token{ident} is the parameter's identifier and
\token{T} is its type. Parameters are separated by a comma. The lifetime of the
parameters are limited to the scope of the function body. Parameters are
variables that adhere to rules that are common to standard variable
declarations, including aspects such as variable lifetime, mutability,
references, laziness, and more. These rules and specific behaviors are detailed
in Chapter~\ref{chap:variables}.

\begin{lstlisting}[style=coloredverbatim]
fn foo (a : i32, b : i32) {
  std::io::println (a, " ", b);
}
\end{lstlisting}

The specification of the parameter's type is obligatory, although its identifier
can be represented by the token \token{\_} to signify that the parameter is not
utilized by the function. Additionally, a parameter beginning and ending with
the token \token{\_} (e.g., \token{\_a\_}) is also flagged as ignorable. Further
details on handling unused variables can be found in
Section~\ref{sec:unused_variables}. While it may initially seem unnecessary,
this convention serves a purpose, particularly in function overriding scenarios
(c.f. Section~\ref{sec:function_overloading}).

\subsubsection*{Calling a function}

A function is called using the syntax \token{ident (arg1, arg2, ...)}, where
\token{ident} is the identifier of the function to call (path to the function
symbol), followed by a list of arguments enclosed in parentheses and separated
by commas. A function argument is a value passed either positionnally or by
keyword as the value to be taken by the parameter of the function when called.
To construct a keyword argument, the parameter identifier is used and associated
with a value using the \token{->} token. The following example shows the call
of the function \token{foo} using both possibilities.

\begin{lstlisting}[style=coloredverbatim]
foo (1, 2); // positional /a/, then /b/

foo (b-> 2, 1); // keyword for /b/, then position for /a/
foo (b-> 2, a-> 1); // keyword for both parameters
\end{lstlisting}

A keyword argument can be placed anywhere in the argument list. The argument
parameter assignment algorithm starts by removing the keyword arguments from the
equation and locking their assignment, and then iterates over the parameters
that do not yet have an assignment to assign them to the positional arguments.
The result of all the above calls is the same, and produce the following Ymir
Intermediate Language code (for the function \token{foo} in the module
\token{main}).

\begin{lstlisting}[style=lyilVerb]
_Y4main3fooFi32i32Zv(1, 2);
_Y4main3fooFi32i32Zv(1, 2);
_Y4main3fooFi32i32Zv(1, 2);
\end{lstlisting}

\warningbox{ the arguments of the function are constructed in the order of
  the parameters, and not in the order they appear in the function call. For
  example, if the function \token{foo} is called as described in the following
  source code, the function \token{bar} will always be called before the function
  \token{baz}. If the order of construction of the arguments is defined and
  predictible, it is not a good habit to count on it, and the use of intermediate
  variables is strongly recommanded to avoid any errors.
}

The following source code produces the Ymir Intermediate Language described in
the code block underneath. At this level, there is no difference between the
three calls, but the third one is preferred for code clarity.

\begin{lstlisting}[style=coloredverbatim]
fn bar ()-> i32 {
  println ("In bar");
  12
}

fn baz ()-> i32 {
  println ("In baz");
  15
}

foo (a-> bar (), b-> baz ());
foo (b-> baz (), bar ());
// if the above code perform the same order of operations, it is recommanded to make it clear

let x = bar ();
let y = baz (); // it is more clear that bar is called before baz
foo (a-> x, b-> y);
\end{lstlisting}
\smallskip

\begin{lstlisting}[style=lyilVerb]
// variable declarations ...
YI_1(#1) = _Y4main3barFZi32();
YI_2(#2) = _Y4main3bazFZi32();
_Y4main3fooFi32i32Zv(YI_1(#1), YI_2(#2)); // first call
YI_3(#3) = _Y4main3barFZi32();
YI_4(#4) = _Y4main3bazFZi32();
_Y4main3fooFi32i32Zv(YI_3(#3), YI_4(#4)); // second call
x(#5) = _Y4main3barFZi32();
y(#6) = _Y4main3bazFZi32();
_Y4main3fooFi32i32Zv(x(#5), y(#6)); // third call
\end{lstlisting}

\subsubsection*{Uniform call syntax}

The Uniform Call Syntax (\textit{UCS}) allows to call any function with the same
syntax as method calls (see Chapter~\ref{chap:custom_types}). The primary use of
this syntax is to chain calls and provide pipe handling to a value by placing
the first argument (associated with the first parameter) before the function
name and concatenating it with the \token{.} token. There is no need to change
the function definition to allow for \textit{UCS}.

\begin{lstlisting}[style=coloredverbatim]
fn add (a : i32, b : i32)-> i32 {
  a + b
}

let a = 12;
let b = a.add (13).add (125); // rewritten into add (add (a, 13), 125)
\end{lstlisting}

\textit{UCS} calls are simply rewritten by placing the left operand of the
binary operation \token{.} as the first positional argument of the call. It is
impossible to use a keyword argument as this left operand. The above source code
produces the following Ymir Intermediate Language result.
\smallskip

\begin{lstlisting}[style=lyilVerb]
let a(#1) : i32;
let YI_2(#2) : i32;
let b(#3) : i32;
a(#1) = 12;
YI_2(#2) = _Y4main3addFi32i32Zi32(a(#1), 13);
b(#3) = _Y4main3addFi32i32Zi32(YI_2(#2), 125);
\end{lstlisting}

\notebox { \textit{UCS} was introduced to perform chained operations. It can be
  compared to function composition in math (but with reverse syntax), where
  \textit{f (g (x))} is rewritten as \textit{x.g ().f ()}. An example of common
  usage is map reduce in the form \token{([1, 2, 3]).map!\{|x| => x + 1\} ().reduce!\{|x, y| => x + y\} ().}
}

\subsubsection*{Optional parameters}

A parameter within a function can have a default value, making it optional to
provide an argument when calling the function. This default value is specified
by appending the \token{=} token after the parameter type, followed by the
desired value. The optional parameter can be placed anywhere in the parameter
list.
\bigskip

\begin{lstlisting}[style=coloredverbatim]
fn foo (a : i32 = 12, b : i32) {
  std::io::println (a, " ", b);
}
\end{lstlisting}

To call the \token{foo} function described in the above code, only one argument
is needed to associate it with the \token{b} parameter. The value of the
parameter can be changed using a keyword argument.

\begin{lstlisting}[style=coloredverbatim]
foo (3); // defining parameter /b/

foo (3, a-> 18); // defining parameter /a/ and /b/
foo (a-> 18, 3); // defining parameter /a/ and /b/
\end{lstlisting}

If no other value is associated with an optional parameter, its default value is
constructed at the place of the call. This means that for a complex default
value (for example, a function call), the value is constructed before entering
the function. For example, let's look at the following code where the parameter
\token{a} has a default value constructed by calling the function \token{bar},
then the function \token{bar} is called before the function \token{foo} when
calling the function \token{foo}. The result is described in the YIL code
below.

\begin{lstlisting}[style=coloredverbatim]
fn bar ()-> i32 {
  println ("In bar.");
  12
}

fn foo (a : i32 = bar ()) {
  println ("In foo : ", a);
}

foo ();
\end{lstlisting}

\begin{lstlisting}[style=lyilVerb]
let YI_1(#1) : i32;
YI_1(#1) = _Y4main3barFZi32();
_Y4main3fooFi32Zv(YI_1(#1));
\end{lstlisting}

The default value of an optional parameter can refer to a symbol that is
accessible within the context of the function for which it is a parameter, but
because the function has not yet been entered and because it would create
complex parameter order dependencies, this value cannot refer to the other
parameters of the function.

\begin{lstlisting}[style=coloredverbatim, escapechar=@]
mod bar {
  pub fn foo (a : i32 = prvInBar ()) {
    println (a);
  }

  fn prvInBar ()-> i32 {
    12
  }
}

bar::foo (); // ok, no need to have access to prvInBar from here because foo has the access

@\hb{bar::prvInBar}@ (); // error, prvInBar is private within this context
\end{lstlisting}

\subsubsection*{Recursive optional parameter}

An optional parameter can be constructed by a function, it can even be
constructed by calling the function in which it is a parameter. However, since
simply calling the function without changing the value of this default parameter
would result in an infinite recursion, in such contexts default values might be
disabled and made mandatory. For example, in the following source code the
validation of the function \token{foo} fails because the parameter \token{a}
is self-dependent. For the same reason, the functions \token{bar} and
\token{baz} are not allowed.

\begin{lstlisting}[style=coloredverbatim]
fn foo (a : i32 = foo ())-> i32 {
  a + 1
}

fn bar (a : i32 = baz ())-> i32 {
  a + 1
}

fn baz (a : i32 = bar ())-> i32 {
  a - 1
}
\end{lstlisting}

To solve this problem, the value of the parameter \token{a} can be set inside
the recursive calls. For example, the following code shows a solution for the
functions \token{bar} and \token{baz}. This fix may seem abrupt, and one could
argue that only one of the two functions needs to stop the infinite recursion.
However, it was decided to force this, as it seems to be a fairly niche problem
that needs to be avoided anyway.

\begin{lstlisting}[style=coloredverbatim]
// setting the option parameter a in baz, to stop the infinite recursion
fn bar (a : i32 = baz (a-> 1))-> i32 {
  a + 1
}

// setting the option parameter a in bar, to stop the infinite recursion
fn baz (a : i32 = bar (a-> 1))-> i32 {
  a - 1
}

bar ();
\end{lstlisting}

The above source code produce the following YIL result.

\begin{lstlisting}[style=lyilVerb]
let YI_1(#1) : i32;
let YI_2(#2) : i32;
YI_1(#1) = _Y4main3bazFi32Zi32(1);
YI_2(#2) = _Y4main3barFi32Zi32(YI_1(#1));
\end{lstlisting}

\subsection {Body, expressions and statements}
\label{sec:function_body}

A function body is an expression that describe a value. There are several types
of expressions in Ymir, some of which have already been described in previous
chapters, such as literal values, binary expressions, etc. A common expression
that is generally used to describe the body of a function is a block. A block is
a list of expressions separated by semicolons and enclosed in curly braces. The
last expression contained in a block may or may not end with a semicolon, 1) if
not, then the value of the block is described by that last expression, 2)
otherwise the block value is a unit value of type \token{void}.

\begin{lstlisting}[style=coloredverbatim]
fn foo (a : i32)-> i32
  a + 1 // body of /foo/

fn bar ()-> i32
{ // start of a block
  let a = 12;
  let b = 34;
  a + b // value of the block
}

fn baz ()-> void {
  let a = 12;
  let b = 34;
  std::io::println (a + b);
} // block value is <unit>

\end{lstlisting}

We can distinguish two kinds of expressions, those that have a value and those
that don't (or actually have the value \token{unit} of type \token{void}). An
expression that has no value is called a statement. Ending an expression with a
semicolon inside a block construction turns it into a statement.

\begin{lstlisting}[style=coloredverbatim, escapechar=@]
fn foo () {
  let a = @\hb{(let b = 12)}@; // error, /let b = 12/ is of type void

  let y = {
    let x = 1;
    x + 1
  };
}
\end{lstlisting}

In the above example at line 2, the statement \token{let b = 12;} does not have
a value, so it cannot be used as the initial value in the variable declaration
of \token{a}. On line 4, however, the expression \token{\{let x = 1; x + 1\}}
has a value and is evaluated to the value \token{2} of type \token{i32}, so it
can be used to describe the initial value of \token{y}. All expressions and
statements are listed in Chapter~\ref{chap:type_and_values}.

\subsubsection*{Empty function}

A function with no body defines a function that is described externally. This
feature is is used to provide header only module files, where source code is
hidden but still callable externally. The actual code of the function has to be
linked at compilation. Let's suppose the two packages \token{foo} and
\token{bar}, where the full source code of the package \token{bar} is
described in \token{bar/src/bar.yr} and a header file was created to be
imported by the package \token{foo} in \token{bar/include/bar.yri}. A
\textit{yri} file described a header file that has been automatically generated
by the compiler (cf. Section\ref{sec:external_decls}).


\begin{lstlisting}[caption=\textit{./bar/src/bar.yr}, style=coloredverbatim]
in bar;
use std::io;

pub fn funcInBar (a : i32)-> i32 {
  println ("Hello from bar");
  a + 1
}
\end{lstlisting}

%\begin{minipage}[t][][t]{0.47\linewidth}
\begin{lstlisting}[caption=\textit{./bar/include/bar.yri}, style=coloredverbatim]
in bar;

pub fn funcInBar (a : i32)-> i32;
\end{lstlisting}
%% \end{minipage}\hspace{5pt}
%% \begin{minipage}[t][][t]{0.47\linewidth}
\begin{lstlisting}[caption=\textit{foo.yr}, style=coloredverbatim]
in foo;

use bar;
use std::io;

pub fn main () {
  println ("Hello from foo");
  println ("Res : ", funcInBar (12));
}
\end{lstlisting}
%\end{minipage}


The file \token{./bar/include/bar.yri} can be published alonside with the
binary file of the \token{bar} package, that way the source code of the package
\token{bar} is hidden. It has the same purpose as header files that could be
found in C/C++ languages.

\begin{lstlisting}[style=bashVerb, escapechar=@+]
@+\textcolor{teal!80}{alice@dev}@+:~$ cd bar/src/
@+\textcolor{teal!80}{alice@dev}@+:~/bar/src$ gyc -c bar.yr -o ../../libbar.o
@+\textcolor{teal!80}{alice@dev}@+:~/bar/src$ cd ../../
@+\textcolor{teal!80}{alice@dev}@+:~$ gyc foo.yr -I bar/include/bar.yri libbar.o -o foo.exe
@+\textcolor{teal!80}{alice@dev}@+:~$ ./foo.exe
Hello from foo
Hello from bar
Res : 13
\end{lstlisting}

\subsection {Return value}

The return type of a function is described at the end of the prototype of a
function declaration, after the parameters, with the syntax \token{-> T}, where
\token{T} is the type returned by the function. This information can be omitted
if the function does not return a value and is therefore of type \token{void}.
The body of the function must produce a value of the same type as that defined
in its prototype.

\begin{lstlisting}[style=coloredverbatim]
fn foo ()-> i32 {
  12
}
fn bar () {}
fn baz ()-> void {}
\end{lstlisting}

The keyword \token{return} can be used to return early, it is associated with a
value written after the keyword, defining the value to return. The type of this
value must be the same as the type of the function.

\begin{lstlisting}[style=coloredverbatim]
fn foo ()-> i32 {
  return 12;
}

fn bar () {
  return; // return with /unit/ value
}
\end{lstlisting}

The value of the function is retreived from the caller of the function, as the
result of the call expression.

\begin{lstlisting}[style=coloredverbatim]
let resultOfFoo = foo ();

// It can also be used inside another expression, as any expression
let add = foo () + 12;
\end{lstlisting}

\subsubsection*{Early exits}
\label{sec:function_early_return}

In case of early return, the type of the body of the function must be
\token{void} if all the branches are leading to an early exit statement. Any
statement and expressions that are not atteignable because they are written
after an early exit are not allowed.

\begin{lstlisting}[style=coloredverbatim, escapechar=@]
fn foo (b : bool)-> i32 {
  if (b) return 12;
  else return 0;

  @\hb{println ("Unreachable !");}@// error, unreachable statement
  @\hb{87}@// unreachable as well
}
\end{lstlisting}

There are three other ways to exit a function early, 1) throw an exception (see
the next subsection), 2) fail an assertion, or 3) panic. All of these early
exits are taken into account by the compiler to compute the exit nodes of the
flow graph and send unreachable statement errors.

\subsection {Exceptions}

A function can exit through various methods, returning normaly and taking the
value of the body, by an early return and taking the value associated with the
return statement, by panicking or by throwing exceptions. The last type of early
exit makes the function unsafe as it exit the function without a value, and
therefore has to be taken into account in the caller function.

It is mandatory to inform in the prototype of the function that it can exit
without returning a value, by using the syntax \token{throws T, U, ...} after
the return type of the function, where \token{T} is a type of exceptions, class
inheriting from the core type \token{core::exception::Exception}. This syntax
lists all the types of exception that can be thrown by the function. Inside the
body of the function the statement \token{throw V;}, with \token{V} a
exception value, exits the function early by throwing an exception.

\begin{lstlisting}[style=coloredverbatim]
fn foo (a : bool)-> i32
  throws AssertError
{
  println ("In foo.");
  if (!a) throw AssertError::new ("a must be true."); // exit the function

  println ("Exiting foo.");
  22 // return the value /22/
}
\end{lstlisting}

When calling the function \token{foo}, thanks to that information, it become
apparent inside the caller that \token{foo} is throwing exception and might
return without a value. The compiler enforce the caller function to take that
into account either by catching the exception, and perform other operations in
case of the failure of the function \token{foo} (this will be treated in
Chapter~\ref{chap:control_flows}), or by enforcing the caller function to also
define in its prototype that exception might be thrown.

\begin{lstlisting}[style=coloredverbatim]
fn bar ()
   throws AssertError
{
  println ("In bar.");
  let x = foo (false) + 32; // /foo/ can throw /AssertError/
  println ("Result of bar : ", x);
}
\end{lstlisting}

Exception might not only exit the function that is throwing the exceptions, but
also the caller functions that are not catching it. If no function catches the
exception (going through all functions until the main function), the program
panics. However, it is easy to avoid program panic due to exception throwing as
it would be apparent in the prototype of the \token{main} function, that the
program might throw an exception. When no exception are displayed in the
prototype of the \token{main} function, then the program cannot panic due to
exception throwing.

In the next code block (calling the \token{bar} function displayed in the
previous code block), the exception is caught. The result of the full program is
displayed in the result block underneath.

\tipbox {
  In the main function, the call to \token{eprintln} has the same prototype
  as the function \token{println}, but write to stderr instead of stdout.
}

\begin{lstlisting}[style=coloredverbatim]
fn main () {
  {
    bar ();
  } catch {
    _ => { // catching all exceptions
      eprintln ("An error occured in bar");
    }
  }
  println ("Normally exiting program.");
}
\end{lstlisting}

\cautionbox { Exceptions should primarily be used for error handling, not for
  routine value checking in control flows. Option values are preferable for
  representing the absence of a value in such scenarios, promoting clearer and
  faster code. }

More information about error handling is presented in
Chapter~\ref{chap:control_flows}. In that chapter will be presented the close
relation between error handling using option values and exception throwing and
how to pass from one to another using Ymir syntax and simple code.

\subsection {Unsafe function}

A function using unsafe without defining an unsafe context has to be tagged as
unsafe. This is done by putting a tag before the prototype of the function using
the syntax \token{@unsafe}.

\importantbox{ This is not perfect, because a function that is not marked as
  unsafe may still perform an unsafe operation, but within an unsafe block
  (e.g., in the next code, the call to \token{baz} is considered safe, but
  it isn't). The same issue exists with panics. There has been an attempt to
  introduce an effect system where functions that use unsafe or panic must
  always declare it, but it has been put aside for the moment. It is difficult
  to design such a system without greatly over-complexifying the code. However,
  it may come back in future versions, in a form close to the Effekt language. }


You cannot just mark all functions that use an unsafe block as unsafe, because
all functions will end up being considered unsafe (many functions from cores and
the standard library use unsafe code that has been verified by hand but cannot
be proven), and just one unsafe function will pollute all callers recursively
back to the main function. In the next example, you can see that the function
\token{baz} is not marked as unsafe, but calls the function \token{foo}, which
uses pointer dereferencing. This is an unsafe operation; in practice, due to the
nature of pointers, there is no way to check the validity of a pointer either at
compile time or at run time, and thus catch an unsafe behavior to make it safe.
Hence, the \token{bar} function is actually unsafe. There is not much we can do
about this, but at least the unsafe behavior is explicitly marked up in the
source code, which reduces the work involved in detecting unsafe code.

\begin{lstlisting}[style=coloredverbatim, escapechar=$]
@unsafe
fn foo () {
  let mut a = 12;
  let dmut b = &a;

  *b = 34; // unsafe, but not in unsafe block
}

fn bar () {
  $\hb{foo ();}$ // error, foo is unsafe but /bar/ isn't
}

fn baz () {
  unsafe { // ok, as foo is unsafe
    foo ();
  }
}
\end{lstlisting}

\subsection{The main function}

A program always starts with a function called \token{main}. This function has
a fixed prototype that must be respected. It can take either no parameter or a
parameter of type \token{[[c8]]}. If a parameter is defined, it takes as value
the list of command line options that were passed to the program when it was
started (the runtime manages the transformation of the C-like parameters
\token{(int, char**)} into a slice of strings).

\begin{lstlisting}[style=coloredverbatim, caption=The simplest main function prototype]
fn main () {
  println ("Hello world!");
}
\end{lstlisting}

The function can either return a value of type \token{i32} or no value
(\textit{unit} value of type \token{void}). It can throw exceptions, i.e. the
program may end in an error when this exception is thrown because it is not
caught by any function. It can also be unsafe.

\begin{lstlisting}[style=coloredverbatim, caption=The most complex main function prototype]
use std::{io, conv}; // for string to int conversion

@unsafe
fn main (args : [[c8]])-> i32
   throws AssertError
{
  println ("Command line options : ", args);
  if (args.len != 2us) throw AssertError::new ("Missing or too much paramters");

  let mut a = args [1].to!{u32} ();
  let dmut b = &a;

  // useless unsafe code, to make the main function unsafe :)
  println ("First parameter is : ", *b);

  *b + 12 // return value of the program
}
\end{lstlisting}

\notebox {
  The \token{main} function is mandatory to create a runnable program, in the
  previous source code examples a lot of code may appear to be written at the root
  level of a file, but that was just for verbosity. All control flow is described
  inside functions, and the first function called is the \token{main} function.
  Only one main function can be described in a program, it can be in any module.
}

\vfill%
\pagebreak

\section{Unit tests}%
\label{sec:unit_test}

Unittest are functions that are not callable. They are defined using the keyword
\token{\_\_test} followed by a body expression. Unlike function, they don't
have identifier and do not take parameters. A test is failing if it throws an
exception, and succeeding if it exits normally.

\begin{lstlisting}[style=coloredverbatim]
__test {
    assert (false, "A test that fails.");
}

__test {
    assert (true, "A test that succeeds.");
}
\end{lstlisting}


Unittest are compiled with the option \token{-funittest}. This option produces
a executable file that launchs the unittest instead of running the function
\token{main}.

\begin{lstlisting}[style=bashVerb, escapechar=@+]
@+\textcolor{teal!80}{alice@dev}@+:~$ gyc -funittest main.yr
\end{lstlisting}

\vfill%
\pagebreak

\section{Global name aliases}
\label{sec:global_alias_names}

A name alias can be used to simplify code by creating a shorthand reference to a
frequently used type or value. This can make the code more readable and easier
to maintain. The keyword \token{def} is used to create a name alias.

\subsection {Using name alias for types}

A name alias can be associated to a type, by using the keyword \token{def}
followed by an identifier, the token \token{:} and finally a type description.

\begin{lstlisting}[style=coloredverbatim]
def String : [c8];

let a : String = "Hello";
\end{lstlisting}

The alias is a global symbol and has access to other symbols as described in
Section~\ref{sec:symbol_protection}. Therefore, they can be used to export
private symbols within a module to external modules under certain conditions. In
the next example, the class \token{A} takes a template parameter that could be
associated with any value, but we only want to export the version that takes the
value \token{"extern"} as a template parameter without defining the class twice.
The alias declaration \token{X} at line 24 comes in handy, allowing this
exportation without making the symbol \token{A} accessible from outside modules.

\begin{lstlisting}[style=coloredverbatim]
use std::io;

mod inner {
    class A {value : [c8]} {
        pub self () {}

        cte if (value == "local") {
            pub fn local (self) {
                println ("Method for local use only");
            }
        } else {
            pub fn external (self) {
                println ("Method for external use");
            }
        }
    }

    pub fn foo () {
        let x = A!{"local"}::new ();
        x.local ();
    }

    // Exporting a specific specialization of A
    pub def X : A!{"extern"};
}


fn main () {
    let x = inner::X::new ();
    x.external ();

    inner::foo ();
}
\end{lstlisting}

This code demonstrates how to use name alias to create flexible and reusable
components while keeping certain implementation details protected within a
module. The above code is just an example, and there might be many other reasons
that justify the use of name aliases, such as code simplification,
maintainability, and abstractions, among others.

\subsubsection*{Type mutability}

The type associated with an alias is always immutable, with its mutability
effectively defined when the alias is used rather than when it is declared. For
example, in the following code, the alias \token{IntArray} is associated with a
\token{[i32]} slice type, and one cannot declare its mutability within the alias
declaration itself. At line 3, when the alias \token{IntArray} is used to
declare a variable, the use of the keyword \token{dmut} makes the type of the
variable deeply mutable. On the other hand, when the keyword \token{dmut} is not
used at line 5, the resulting type is \token{mut [i32]} instead of \token{mut
  [mut i32]}.

\begin{lstlisting}[style=coloredverbatim, escapechar=@]
def IntArray : @\hb{dmut}@ [i32]; // error, mutability change is not allowed here

let dmut a : IntArray = copy [1, 2, 3]; // inner values are mutable, due to dmut
let mut b : IntArray = a; // inner values are not mutable, no need to alias a

b [0] @\hb{=}@ 9; // mutability of IntArray is const by default
\end{lstlisting}

The reason for not allowing mutability change directly from the alias
declaration is to avoid hidden mutability changes. If the keywords \token{mut}
and \token{dmut} were not visible at the location of the variable declaration,
it would create a situation where the variable has mutable access to its data
without clear indication. This would necessitate checking the alias declaration
to ensure such hidden behavior does not occur. This approach contradicts the
philosophy of the Ymir language, which aims to place all behavior explanations
at the location where they effectively have an impact, thereby avoiding the
dispersion of information across the code.

\subsection{Using name alias for values}

A value can be associated to an alias name using a syntax close to the one used
to declare a type name alias, but by replacing the token \token{:} by the token
\token{=}.

\begin{lstlisting}[style=coloredverbatim]
def SuccessMessage = "Success !";
def ErrorMessage = "Failure..";

let test : bool = // ...;
if test {
  println (SuccessMessage);
} else {
  println (ErrorMessage);
}
\end{lstlisting}

As a name alias for a type, a name alias to a value is a global symbol, and thus
can be used to export private symbol to external modules under certain
conditions. In the next example, the function \token{foo} is not accessible fro
the the \token{main} function while the global alias \token{F} is. For that
reason at line 18 and 19, the function \token{foo} can be called using the alias
\token{F} that export an alias to the function prototype symbols. In this
example, the name alias actually exports an alias to multiple symbols - the two
functions \token{foo} declared within the module \token{inner}. It is during the
call expressions at line 18 and 19 that the a specialization is performed (at
compile time) to decide which of the two symbols is used.

\begin{lstlisting}[style=coloredverbatim]
use std::io;

mod inner {

  fn foo (i : i32) {
    println ("In first foo : ", i);
  }

  fn foo (i : i32, j : i32) {
    println ("In second foo : ", i + j);
  }

  pub def F = inner::foo; // with inner:: to make sure no other foo functions are aliased
}

fn main () {
  inner::F (12);
  inner::F (12, 23);
}
\end{lstlisting}

\subsubsection*{Value alias construction}

A name alias exists only during compile time, and therefore has no memory
location at runtime. It is not a constant global variable. For that reason, the
value attached to a name alias is constructed each time it is referenced. In the
next example, the name alias \token{F} is attached to a value that calls the
function \token{foo}. This alias is referenced twice at line 9 and 10, therefore
the function \token{foo} is called twice.

\begin{lstlisting}[style=coloredverbatim]
fn foo ()-> i32 {
  println ("Calling foo");
  12
}

def F = foo ();

fn main () {
  let _ = F;
  let _ = F;
}
\end{lstlisting}


This behavior has other implications, firstly because name aliases have no
memory location and are simply shorthands for constructing values, they cannot
be changed, and have no memory address.

\begin{lstlisting}[style=coloredverbatim, escapechar=@]
def V = 12;
def A = copy [1, 2, 3];

V @\hb{=}@ 89; // error, V is not a lvalue
A [0] @\hb{=}@ 8; // error, A is not an lvalue either
\end{lstlisting}

Secondly, when it involves value allocations and memory borrowing. In the next
example, the variable \token{a} and \token{b} borrows two different slices, that
are constructed when referencing the name alias \token{A}.

\begin{lstlisting}[style=coloredverbatim]
def A = copy [1, 2, 3];

let dmut a = A;
let dmut b = A;

a [0] = 9;
assert (b [0] == 1);
\end{lstlisting}

One could arguee that in this example, from the perspective of the variables
\token{a} and \token{b} an hidden allocation is performed. It was chosen to
allow this kind of behavior as the same observation can be made when calling a
function that returns an allocated value without needing the use of an
\token{alias} nor a new \token{copy}. From that understanding, a value name
alias can be seen as a function call that takes no parameter and that is inlined
at compile time.

\begin{lstlisting}[style=coloredverbatim]
fn foo ()-> dmut [i32];
def A = copy [1, 2, 3];

let dmut a = foo ();
let dmut b = A;
\end{lstlisting}

\vfill%
\pagebreak

\section{Global variable}%
\label{sec:global_variables}

A global variable is declared as a global symbol (within a module) using the
keyword \token{lazy} followed by an identifier. Global variables are thoroughly
presented in Chapter~\ref{chap:variables}.

\begin{lstlisting}[style=coloredverbatim]
lazy A = 12;

// Global variable protection system is the same as any global symbol
pub lazy B = A;
\end{lstlisting}

Global variables in Ymir are inherently lazy, meaning they are instantiated and
constructed only upon their first reference at runtime. This design addresses
the complexity arising from global variables referencing each other across
different modules. Constructing a dependency graph of symbols to ensure that
dependent global variables are created in the correct order would require a
sophisticated system. Such a system would be extremely complex to build and
sometimes impossible, as cycles could exist without being visible at compile
time (e.g., global variables from external packages). Hence, the lazy
instantiation approach simplifies this process. Laziness ensures that when a
global variable references another global variable, the referenced variable is
necessarily constructed.

\begin{lstlisting}[style=coloredverbatim]
lazy A = foo (); lazy B = bar (A);

fn foo ()-> i32 {
  println ("In foo");
  42
}

fn bar (a : i32)-> i32 {
  println ("In bar")
  a * 2
}

fn main () {
  println ("In main");
  println ("B = ", B); // first reference to B in the program
  println ("A = ", A); // second reference to A in the program
}
\end{lstlisting}

In the above listing, the construction of the global variable \token{B} depends
on the value of the global variable \token{A}. In other C-like languages (C++,
D, etc.), this would be problematic as there would be no guarantee that
\token{A} would be constructed before \token{B}. Thanks to the lazy system, when
the variable \token{B} is constructed, it triggers the construction of the
variable \token{A}. Therefore, \token{A} always has a value when \token{B} is
being constructed. The result of the above source code is presented in the next
listing.

\begin{lstlisting}[style=bashVerb, escapechar=@+]
In main
In foo
In bar
B = 84
A = 42
\end{lstlisting}

\vfill%
\pagebreak

\section{External declaration}%
\label{sec:extern_var}

External variable
