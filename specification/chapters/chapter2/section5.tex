\section{Floating point types}

Numbers that include a decimal point are called floating-point numbers in Ymir.
Unlike integers, floating-point numbers have a limited precision that depends on
how many bytes are used to store them. Ymir provides four floating-point types:
\token{f32}, \token{f64}, \token{f80}, and \token{fsize}. As with integer types,
the number after the letter \token{f} indicates the number of bits used in
memory for that type, while \token{fsize} is architecture-dependent and
corresponds to the largest floating-point representation supported by the
machine.

\subsection{Floating point literals}

A floating-point literal consists of two integer parts separated by a decimal
point \token{.}, with no spaces in between. As with integer literals, the
underscore \token{\_} can be used to separate digits in long numbers to improve
readability.

\noindent{}By default, a floating-point literal is of type \token{f64}. However, it is
possible to explicitly choose another type by adding a suffix: \token{f} for
\token{f32}, \token{d} for \token{f64}, \token{l} for \token{f80}, and \token{r}
for \token{fsize}.

\begin{lstlisting}[style=coloredVerbatim, label=lst:(chap2):float_literal, caption=Example of floating point literals]
let x = 3.14_15_92f; // f32

let y = 2.71828d; // f64
let z = 2.71828; // f64

let w = 1.0l; // f80

let v = 1_000.0r; // fsize
let u = 1.888_999r; // fsize
\end{lstlisting}

\mynotebox{
  More advanced forms of floating-point literals are also available,
  such as hexadecimal notation and scientific notation. These representations
  are explained in detail in the advanced chapter on floating-point types (see
  Chapter~\ref{sec:(chap3):floats}).
}

\subsection{Memory representations}

Floating-point numbers follow the IEEE-754 standard, which defines how values
are represented in memory. According to this standard, each floating-point value
is divided into three distinct parts: the sign, the exponent, and the mantissa
(also called the significand). The number of bits allocated to each part depends
on the specific floating-point type.

\input{chapters/chapter2/figures/float_size}

The value of a floating-point number is computed using the following formula,
where the sign is either $+1$ or $-1$, and the bias is defined as $bias =
2^{e-1} - 1$ with $e$ representing the number of bits used for the exponent. For
instance, in the \token{f32} type, $e = 8$, which gives a bias of $127$.

\begin{equation*}
  value = sign \times mantissa \times 2^{(exponent - bias)}
\end{equation*}

Using a bias allows the exponent to range from negative to positive values
without needing a separate sign bit for the exponent, which simplifies hardware
design and makes arithmetic more efficient (e.g., the exponant of $0$ is
represented by $127$, $1$ by $128$ and $-1$ by $126$). As a result positive and
negative exponents are distributed evenly around zero. For \token{f32}, the
actual exponent ranges roughly from $-126$ to $127$.

\subsubsection{Example}

Let us consider the memory representation of the number $87.25$ as an
\token{f32} floating-point value. To begin, we convert the number to binary. The
integer part, $87$, is represented as $1010111_2$, while the fractional part,
$0.25$, is represented as $0.01_2$, since $0.25 = 0 \times 2^{-1} + 1 \times
2^{-2} + 0 \times 2^{-3} + \ldots$. Combining these parts, we obtain the binary
representation $1010111.01_2$. This number is then normalized into the form
$1.mantissa \times 2^{exponent}$, yielding $1.01011101 \times 2^{6}$. From this, we see
that the exponent is $6$, and because the number is positive, the sign bit is
$0$.

\smallskip{}
\noindent{}As explained earlier, the exponent in IEEE-754 representation is
stored with a bias, which is $127$ for the \token{f32} type. In our case, the
exponent is $6$, so the stored value is $6 + 127 = 133$. Written in binary on 8
bits, this gives $10000101_2$. The mantissa corresponds to the fractional part
of the normalized binary number $1.01011101$, excluding the leading 1, and is
padded with zeros to reach the 23-bit length required by the format. The
complete memory representation of $87.25$ as an \token{f32} value is summarized
in Table~\ref{tab:(chap2):float_mem_repr_ex}.

\begin{table}[h!]
  \centering
  \label{tab:integer_ranges}
  \begin{tabular}{p{.15\textwidth}|p{.25\textwidth}|p{0.25\textwidth}}
    \toprule[0.6pt]
    \textbf{Sign} & \textbf{Exponent} & \textbf{Mantissa} \\
    \toprule[0.6pt]
    $0$    & $10000101$ & $01011101000000000000000$ \\
    \bottomrule[0.2pt]
  \end{tabular}
  \caption{\label{tab:(chap2):float_mem_repr_ex} Memory representation of $87.25$ in a \token{f32}}
\end{table}

\subsection{Stepping}

The precision of a floating-point type determines how finely it can
distinguish between two values. Because there is an infinite number of values
between any two decimal numbers, it is impossible to represent them all with a
fixed number of bits. As a result, some numbers cannot be stored exactly, and
the closest available value is used instead. This limitation is called
\textit{stepping}, and it is important to keep in mind that not every decimal
number can be represented exactly by a floating-point value.

\smallskip{}
\noindent{}Listing~\ref{lst:(chap2):stepping_example} illustrates an example of
stepping. In this example, even though an opposite operation is performed to
compute the value of the variable \token{w} from the value of \token{y}, the
result appears slightly different due to stepping, causing \token{z} and
\token{w} to differ. Here, \token{f32} values are used; replacing them with
\token{f64} values removes the discrepancy for this particular case.
Floating-point values stored in 64 bits provide higher accuracy than 32-bit
values, but they are still subject to stepping errors in general.

\begin{lstlisting}[style=coloredVerbatim, label=lst:(chap2):stepping_example, caption=Example of floating point stepping]
  let z = 1.989328f; // 'f' suffix to create a f32 literal
  let mut x = 0.98769778678f;
  let mut y = z - x;

  let w = x + y;

  println ("(X : ", x, ", Y : ", y, ")");
  println ("(Z : ", z, ", W : ", w, ")");
  println ("Z == W : ", z == w);
\end{lstlisting}
\vspace{-10pt}%
\begin{lstlisting}[style=bashVerb]
  (X : 0.987698, Y : 1.00163)
  (Z : 1.98933, W : 1.98933)
  Z == W : false
\end{lstlisting}

\subsection{Special values}

In addition to normal numbers, the IEEE-754 standard defines special
representations for infinity, NaN (Not a Number), and zero, using particular
patterns in the exponent and mantissa fields.

\input{chapters/chapter2/figures/special_float_numbers}
