in lexer;
    
use ymirc::lexing::{word, tokens};
use ymirc::utils::list;

use std::syntax::tokenizer;
use std::{stream, io};

/**
 * The lexer is the class responsible of cutting a source code string into a list of tokens
 * Unlike simple tokenizer, the lexer has context information, and switch (allowing to ignore parts of the source code, or not depending of the context)
 */
@final
pub class Lexer {
    
    // The name of the file that the lexer is reading
    let _filename : [c8];

    // The content of the file, that is tokenized
    let _content : [c8];

    // Does the lexer has to skip comments
    let mut _doComments = true;

    // The position of the cursor
    let mut _cursor = 0us;

    // The current word that is being read
    let mut _wordCursor = 0us;

    // The list of words infos
    let mut _wordInfos : [(usize, bool, [c8])] = [];

    // The end comments that are found
    let dmut _commentEnds : [usize => (usize, usize)] = copy [];

    // The list of allocated words found in the files (the tokens basically)
    let mut _words : [&Word] = [] ;
    
    // The position of the (cursors, line, col, lineSeek) of the previous read words
    let dmut _rewinders : &List!{(usize, usize)} = copy List!{(usize, usize)} ();

    // Set to true, when nothing is left to read (iif _cursor >= _content.len)
    let mut _eof : bool = false;

    // The word returns when the lexer is eof
    let _eofWord : &Word;

    let _initLine : u64;
    let _initCol : u64;
    let _initLineSeek : usize;

    /**
     * Create a new lexer, ready to split content
     * @params: 
     *    - content: the content to split
     *    - tokens: the list of tokens that split the string, (cf. Tokenizer)
     *    - comments: the list of tokens that start a comment line (by default [])
     *    - skips: the list of tokens that will be omitted by the lexer when reading (by default [" ", "\n", "\t", "\r"])
     * @warning: if the skips and comments token are not in tokens, they are added, so they split the content 
     */
    pub self (filename : [c8], content : [c8], tokens: [[c8]], comments : [([c8], [c8])], skips: [[c8]], addLine : u64 = 1u64, addCol : u64 = 1u64, lineSeek : usize = 0us)
        with _filename = filename
        , _content = content
        , _eofWord = copy Word::eof (filename-> filename)
        , _initLine = addLine
        , _initCol = addCol
        , _initLineSeek = lineSeek
    {
        self._rewinders:.push ((self._cursor, self._wordCursor));

        let mut tzer = Tokenizer!{c8} (tokens-> tokens);
        for i in comments {
            tzer:.insert (i._0, isComment-> i._1);
        }

        for i in skips {
            tzer:.insert (i, isSkip-> true);
        }

        self:.readAll (tzer);
    }        

    /**
     * Read the next word in the lexer, and returns it, with the documentation read before it
     * @returns:
     *   - .0: the next word in the lexer
     *   - .1: the associated comments
     */
    pub fn next (mut self)-> (&Word, [c8]) {
        if (self._eof) return (self._eofWord, "");

        self._rewinders:.push ((self._cursor, self._wordCursor));
        let mut start_com = 0us;
        let mut end_com = 0us;

        while (self._wordCursor < self._wordInfos.len) {
            let (wd, isSkip, isComment) = self._wordInfos [self._wordCursor];
            self._wordCursor += 1us;
            self._cursor += wd;
            if (!isSkip) {
                if (isComment != "") {
                    start_com = self._cursor - wd;
                    self:.gotoNextToken (isComment, self._words [self._wordCursor - 1].str);
                    end_com = self._cursor;
                    if (self._words [self._wordCursor - 1us] == (CommentTokens::MULTILINE_NO_DOC)._0) { start_com = end_com; }
                } else {
                    return (self._words [self._wordCursor - 1us], self._content [start_com .. end_com]);
                }
            }
        }

        self._eof = true;
        return (self._eofWord, "");
    }

    /**
     * Read the next word in the lexer, and returns it, with the documentation read before it
     * @returns:
     *   - .0: the next word in the lexer
     *   - .1: the associated comments
     */
    pub fn nextNoConsume (self)-> (&Word, [c8]) {
        if (self._eof) return (self._eofWord, "");
        let mut start_com = 0us;
        let mut end_com = 0us;

        let mut saveWC = self._wordCursor, mut saveC = self._cursor;
        while (saveWC < self._wordInfos.len) {
            let (wd, isSkip, isComment) = self._wordInfos [saveWC];

            saveWC += 1us;
            saveC += wd;
            if (!isSkip) {
                if (isComment != "") {
                    start_com = saveC - wd;
                    let (postWC, postC) = self.gotoNextTokenNoConsume (isComment, self._words [saveWC - 1].str, saveWC, saveC);
                    saveWC = postWC;
                    saveC = postC;
                    end_com = saveC;
                    if (self._words [saveWC - 1us] == (CommentTokens::MULTILINE_NO_DOC)._0) { start_com = end_com; }
                } else {
                    return (self._words [saveWC - 1us], self._content [start_com .. end_com]);
                }
            }
        }

        return (self._eofWord, "");
    }

    /**
     * @returns: the next word, without taking into account skips, and comments
     */
    pub fn directNext (mut self)-> &Word {
        if (self._eof) return self._eofWord;
        
        self._rewinders:.push ((self._cursor, self._wordCursor));
        if (self._wordCursor < self._wordInfos.len) {
            self._wordCursor += 1us;
            self._cursor += self._wordInfos [self._wordCursor - 1us]._0;
            self._words [self._wordCursor - 1us]
        } else {
            self._eof = true;
            self._eofWord
        }
    }
    
    /**
     * Got to the end of a string disabling skip tokens
     * @params: 
     *    - closing: the token closing the string
     * @returns: 
     *   - .0 : the content of the string literal
     *   - .1 : the closing word
     */
    pub fn getString (mut self, closing : [c8], opening : [[c8]] = [], escaping : bool = false)-> ([c8], &Word) {
        let start = self._cursor;
        let mut nb = 1us;
        let mut currentEscape = false;
        while (self._wordCursor < self._wordInfos.len) {
            let (wd, _, _) = self._wordInfos [self._wordCursor];

            let ret = self._content [self._cursor .. self._cursor + wd];
            self._wordCursor += 1us;
            self._cursor += wd;
                
            if (ret == closing && !currentEscape) {
                nb -= 1us;
                if (nb == 0us) {
                    return (self._content [start .. self._cursor - wd], self._words [self._wordCursor - 1us]);
                }
            } else if (!currentEscape) {
                for j in opening {
                    if ret == j {
                        nb += 1us;
                        break;
                    }
                }
            }

            currentEscape = escaping && !currentEscape && (ret == Tokens::ANTI);
        }

        self._eof = true;
        return (self._content [start .. $], self._eofWord);
    }


    /**
     * @returns:
     *    - .0: the string that was read so far as the location of the current word cursor
     *    - .1: the rest of the string that was not yet read
     * */
    pub fn getCutContent (self)-> ([c8], [c8]) {
        let beg = self._content [0us .. self._cursor];
        let end = self._content [self._cursor .. $];

        (beg, end)
    }

    /*!
     * ================================================================================
     * ================================================================================
     * =========================            REWIND            =========================
     * ================================================================================
     * ================================================================================
     */
    
    /**
     * Rewind to a previous location in the file
     * Each time the function next is called, the lexer saves the cursor position
     * This function rewind go to that cursor position, so if we rewind 10 times, we will get the last 10 next calls
     * @warning: 
     * ===============
     * when toggeling skips, and doComment, the rewind does not garantee, that the lexer will return at least nb tokens
     * ===============
     */
    pub fn rewind (mut self) {
        if (self._eof) {
            self._rewinders:.pop ();
            self._eof = false;
        }

        let (x, h) = self._rewinders.back ();
        self._cursor = x;
        self._wordCursor = h;

        self._rewinders:.pop ();
        if (self._rewinders.isEmpty ()) {
            self._rewinders:.push ((self._cursor, self._wordCursor));
        }
    }

    /**
     * Rewind to a previous location in the file, moving the c8 cursor
     * @params: 
     *   - cursor: the c8 seek cursor to go to 
     */
    pub fn rewindToSeek (mut self, cursor : usize) {
        if (self._eof) {
            self._rewinders:.pop ();
            self._eof = false;
        }

        while self._rewinders.len > 0 {
            let (x, h) = self._rewinders.back ();
            self._cursor = x;
            self._wordCursor = h;
            self._rewinders:.pop ();
            if (x <= cursor) break;
        }

        if (self._rewinders.len == 0us) {
            self._rewinders:.push ((self._cursor, self._wordCursor));
        }
    }

    /***
     * ============================================================================
     * ============================================================================
     * =========================          GETTERS        ==========================
     * ============================================================================
     * ============================================================================
     */
    
    /**
     * @returns: the counter of previous "self:.next" calls
     * @info: this information can be usefull to go back rapidely
     * @example: 
     * =================
     * let dmut lex : &Lexer = ...
     * let read_Nb : u64 = ...
     * let cursor = lex.getSeek ();
     * for i in 0 .. read_Nb {
     *     println (lex:.next ()._0);
     * }
     * lex:.rewindToSeek (cursor); // go back of number of valid read done
     * // so the lexer will be reset, as if the for loop never executed
     * =================
     */
    pub fn getSeek (self)-> usize {
        self._cursor
    }

    /***
     * ============================================================================
     * ============================================================================
     * =========================          PRIVATE        ==========================
     * ============================================================================
     * ============================================================================
     */
    
    /**
     * Move the cursor (and counters) to the next token == end
     */
    prv fn gotoNextToken (mut self, end : [c8], opening : [c8])-> void {
        let start = self._wordCursor;
        if let Ok (x) = self._commentEnds [self._wordCursor] {
            self._wordCursor = x._0;
            self._cursor = x._1;
            return;
        }

        if tokens::isMultipleLineComment (opening) {
            let mut finish = 0us;
            while (self._wordCursor < self._wordInfos.len) {
                let (wd, _, _) = self._wordInfos [self._wordCursor];
                let ret = self._content [self._cursor .. self._cursor + wd];
                self._wordCursor += 1us;
                self._cursor += wd;

                if (ret == end) {
                    if (finish == 0us) {
                        self._commentEnds [start] = (self._wordCursor, self._cursor);
                        return;
                    } else finish -= 1us;
                } else if ret == opening {
                    finish += 1us;
                }
            }
        } else {
            while (self._wordCursor < self._wordInfos.len) {
                let (wd, _, _) = self._wordInfos [self._wordCursor];
                let ret = self._content [self._cursor .. self._cursor + wd];
                self._wordCursor += 1us;
                self._cursor += wd;

                if (ret == end) {
                    self._commentEnds [start] = (self._wordCursor, self._cursor);
                    return;
                }
            }
        }

        self._commentEnds [start] =  (self._wordCursor, self._cursor);
    }

    /**
     * Move the cursor (and counters) to the next token == end
     */
    prv fn gotoNextTokenNoConsume (self, end : [c8], opening : [c8], wordCursor : usize, cursor : usize)-> (usize, usize) {
        if let Ok (x) = self._commentEnds [wordCursor] {
            return (x._0, x._1);
        }

        let mut saveWC = wordCursor, mut saveC = cursor;
        if tokens::isMultipleLineComment (opening) {
            let mut finish = 0us;
            while (saveWC < self._wordInfos.len) {
                let (wd, _, _) = self._wordInfos [saveWC];
                let ret = self._content [saveC .. saveC + wd];
                saveWC += 1us;
                saveC += wd;

                if (ret == end) {
                    if (finish == 0us) {
                        return (saveWC, saveC);
                    } else finish -= 1us;
                } else if ret == opening && isMultipleLineComment (opening) {
                    finish += 1us;
                }
            }
        } else {
            while (saveWC < self._wordInfos.len) {
                let (wd, _, _) = self._wordInfos [saveWC];
                let ret = self._content [saveC .. saveC + wd];
                saveWC += 1us;
                saveC += wd;

                if (ret == end) {
                    return (saveWC, saveC);
                }
            }
        }

        return (saveWC, saveC);
    }

    /**
     * Read the content to lex, and store the words
     */
    prv fn readAll (mut self, tzer : Tokenizer!{c8}) {
        let mut tzerCursor = 0us;
        let mut lineSeek = self._initLineSeek;
        let mut line = self._initLine;
        let mut col = self._initCol;

        let dmut wordInfos = copy List!{(usize, bool, [c8])} ();
        let dmut words = copy List!{dmut &Word} ();

        loop {
            let (len, isSkip, isComment) = tzer.next (self._content [tzerCursor .. $]);
            if (len == 0us) break;

            let ret = self._content [tzerCursor  .. tzerCursor + len];
            wordInfos:.push ((len, isSkip, isComment));
            words:.push (copy Word (ret, filename-> self._filename, fileContent-> self._content, line, col, tzerCursor, lineSeek));
            tzerCursor += len;

            if (ret [0us] == '\n'c8) {
                lineSeek = lineSeek + cast!usize (col);
                line += 1u64;
                col = 1u64;
            } else { col += cast!u64 (len); }
        }

        self._wordInfos = wordInfos:[];
        self._words = words:[];
    }

    /***
     * ==================================================================================
     * ==================================================================================
     * =========================          MISCELLANEOUS        ==========================
     * ==================================================================================
     * ==================================================================================
     */
    
    impl Streamable;
    
    
}
