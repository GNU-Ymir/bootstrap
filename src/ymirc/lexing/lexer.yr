mod ymirc::lexing::lexer;
    
import ymirc::lexing::word;
import ymirc::lexing::tokens;
import ymirc::lexing::tokenizer;

import std::io;
import std::collection::vec;
import std::collection::map;
import std::collection::set; 
import std::time::_;

/**
 * The lexer is the class responsible of cutting a source code string into a list of tokens
 * Unlike simple tokenizer, the lexer has context information, and switch (allowing to ignore parts of the source code, or not depending of the context)
 */
pub class @final Lexer {
    
    /// The name of the file that the lexer is reading
    let _filename : [c8];

    /// The content of the file, that is tokenized
    let _content : [c8];

    /// Does the lexer has to skip comments
    let mut _doComments = true;

    /// The position of the cursor
    let mut _cursor = 0us;

    /// The current word that is being read
    let mut _wordCursor = 0us;

    /// The list of words infos
    let mut _wordInfos : [(usize, bool, [c8], [[c8]])] = [];

    /// The end comments that are found
    let dmut _commentEnds = HashMap!{usize, (usize, usize)}::new ();

    /// The list of allocated words found in the files (the tokens basically)
    let mut _words : [&Word] = [] ;
    
    /// The position of the (cursors, line, col, lineSeek) of the previous read words 
    let dmut _rewinders = Vec!{(usize, usize)}::new ();

    /// Set to true, when nothing is left to read (iif _cursor >= _content.len)
    let mut _eof : bool = false;

    /// The word returns when the lexer is eof
    let _eofWord : &Word;

    /**
     * Create a new lexer, ready to split content
     * @params: 
     *    - content: the content to split
     *    - tokens: the list of tokens that split the string, (cf. Tokenizer)
     *    - comments: the list of tokens that start a comment line (by default [])
     *    - skips: the list of tokens that will be omitted by the lexer when reading (by default [" ", "\n", "\t", "\r"])
     * @warning: if the skips and comments token are not in tokens, they are added, so they split the content 
     */
    pub self (filename : [c8], content : [c8], tokens: [[c8]] = [" "s8], comments : [([c8], [c8], [[c8]])] = [], skips: [[c8]] = [" "s8, "\n"s8, "\t"s8, "\r"s8])
        with _filename = filename, _content = content, _eofWord = Word::eof (filename-> filename)
    {
        self._rewinders:.push ((self._cursor, self._wordCursor));

        let dmut tzer = Tokenizer::new (tokens-> tokens);
        for i in comments {
            tzer:.insert (i._0, isComment-> i._1, opening-> i._2);
        }

        for i in skips {
            tzer:.insert (i, isSkip-> true);
        }

        self:.readAll (alias tzer);
    }        

    /**
     * Read the next word in the lexer, and returns it, with the documentation read before it
     * @returns: 
     *   - .0: the next word in the lexer
     *   - .1: the associated comments
     */
    pub def next (mut self)-> (&Word, [c8]) {
        if (self._eof) return (self._eofWord, ""s8);
        
        self._rewinders:.push ((self._cursor, self._wordCursor));
        let mut start_com = 0us;
        let mut end_com = 0us;

        while (self._wordCursor < self._wordInfos.len) {
            let (wd, isSkip, isComment, opening) = self._wordInfos [self._wordCursor];

            self._wordCursor += 1us;
            self._cursor += wd;
            if (!isSkip) {
                if (isComment != ""s8) {
                    start_com = self._cursor - wd;
                    self:.gotoNextToken (isComment, opening-> opening);
                    end_com = self._cursor;
                    if (self._words [self._wordCursor - 1us] == (CommentTokens::MULTILINE_NO_DOC)._0) { start_com = end_com; }
                    } else {
                    return (self._words [self._wordCursor - 1us], self._content [start_com .. end_com]);
                }
            }
        }

        self._eof = true;
        return (self._eofWord, ""s8);
    }

    /**
     * @returns: the next word, without taking into account skips, and comments
     */
    pub def directNext (mut self)-> &Word {
        if (self._eof) return self._eofWord;
        
        self._rewinders:.push ((self._cursor, self._wordCursor));
        if (self._wordCursor < self._wordInfos.len) {
            self._wordCursor += 1us;
            self._cursor += self._wordInfos [self._wordCursor - 1us]._0;
            self._words [self._wordCursor - 1us]
        } else {
            self._eof = true;
            self._eofWord
        }
    }
    
    /**
     * Got to the end of a string disabling skip tokens
     * @params: 
     *    - closing: the token closing the string
     *    - opening: the token that reopen the string, assuming that a string must be balanced
     * @returns: 
     *   - .0 : the content of the string literal
     *   - .1 : the closing word
     */
    pub def getString (mut self, closing : [c8], opening : [[c8]] = [], escaping : bool = false)-> ([c8], &Word) {
        let start = self._cursor;
        let mut nb = 1us;
        let mut currentEscape = false;
        while (self._wordCursor < self._wordInfos.len) {
            let (wd, _, _, _) = self._wordInfos [self._wordCursor];

            let ret = self._content [self._cursor .. self._cursor + wd];
            self._wordCursor += 1us;
            self._cursor += wd;
                
            if (ret == closing && !currentEscape) {
                nb -= 1us;
                if (nb == 0us) {
                    return (self._content [start .. self._cursor - wd], self._words [self._wordCursor - 1us]);
                }
            } else if (!currentEscape) {
                for j in opening {
                    if ret == j {
                        nb += 1us;
                        break {}
                    }
                }
            }

            currentEscape = escaping && !currentEscape && (ret == Tokens::ANTI);
        }

        self._eof = true;
        return (self._content [start .. $], self._eofWord);
    }

    /**
     * ================================================================================
     * ================================================================================
     * =========================            REWIND            =========================
     * ================================================================================
     * ================================================================================
     */
    
    /**
     * Rewind to a previous location in the file
     * Each time the function next is called, the lexer saves the cursor position
     * This function rewind go to that cursor position, so if we rewind 10 times, we will get the last 10 next calls
     * @warning: 
     * ===============
     * when toggeling skips, and doComment, the rewind does not garantee, that the lexer will return at least nb tokens
     * ===============
     */
    pub def rewind (mut self, nb : u64 = 1u64) {
        if (self._eof) {
            self._rewinders:.pop (1u64);
            self._eof = false;
        }
        
        if (nb > 1u64) self._rewinders:.pop (nb - 1u64);    
        
        let (x, h) = self._rewinders[][self._rewinders.len () - 1us] ;
        self._cursor = x;
        self._wordCursor = h;
                
        self._rewinders:.pop (1u64);    
        if (self._rewinders.len () == 0us) {
            self._rewinders:.push ((self._cursor, self._wordCursor));
        }

        
    }

    /**
     * Rewind to a previous location in the file, moving the wordCursor
     * @params: 
     *   - nb: the word cursor to go to 
     */
    pub def rewindTo (mut self, nb : u64) {
        if (self._eof) {
            self._rewinders:.pop (1u64);
            self._eof = false;
        }

        while cast!u64 (self._rewinders.len ()) > nb {
            let (x, h) = self._rewinders[][self._rewinders.len () - 1us] ;
            self._cursor = x;
            self._wordCursor = h;
            self._rewinders:.pop (1u64);            
        }

               
        if (self._rewinders.len () == 0us) {
            self._rewinders:.push ((self._cursor, self._wordCursor));
        }
    }

    /**
     * Rewind to a previous location in the file, moving the c8 cursor
     * @params: 
     *   - cursor: the c8 seek cursor to go to 
     */
    pub def rewindToSeek (mut self, cursor : u64) {
        if (self._eof) {
            self._rewinders:.pop (1u64);
            self._eof = false;
        }
                
        loop {
            if (self._rewinders.len () == 0us) break {}            
            let (x, h) = self._rewinders[][self._rewinders.len () - 1us] ;
            self._cursor = x;
            self._wordCursor = h;
            self._rewinders:.pop (1u64);
            
            if (x <= cursor) break {}
        }

        if (self._rewinders.len () == 0us) {
            self._rewinders:.push ((self._cursor, self._wordCursor));
        }
    }

    /***
     * ============================================================================
     * ============================================================================
     * =========================          GETTERS        ==========================
     * ============================================================================
     * ============================================================================
     */
    
    /**
     * @returns: the counter of previous "self:.next" calls
     * @info: this information can be usefull to go back rapidely
     * @example: 
     * =================
     * let dmut lex : &Lexer = ...
     * let read_Nb : u64 = ...
     * let counter = lex.getCounter ();
     * for i in 0 .. read_Nb {
     *     println (lex:.next ()._0);
     * }
     * lex:.rewind (nb-> lex.getCounter () - counter); // go back of number of valid read done
     * // so the lexer will be reset, as if the for loop never executed
     * =================
     */
    pub def getCounter (self)-> u64 {
        cast!u64 (self._rewinders.len ())
    }

    

    /***
     * ============================================================================
     * ============================================================================
     * =========================          PRIVATE        ==========================
     * ============================================================================
     * ============================================================================
     */
    
    /**
     * Move the cursor (and counters) to the next token == end
     */
    prv def gotoNextToken (mut self, end : [c8], opening : [[c8]] = [])-> void {
        let start = self._wordCursor;
        match self._commentEnds.find (self._wordCursor) {
            Ok (x : _) => {
                self._wordCursor = x._0;
                self._cursor = x._1;
                return {}
            }
            _ => {
                let mut finish = 0us;
                while (self._wordCursor < self._wordInfos.len) {
                    let (wd, _, _, _) = self._wordInfos [self._wordCursor];
                    let ret = self._content [self._cursor .. self._cursor + wd];
                    self._wordCursor += 1us;
                    self._cursor += wd;

                    if (ret == end) {
                        if (finish == 0us) {
                            self._commentEnds:.insert (start, (self._wordCursor, self._cursor));
                            return {}
                        } else finish -= 1us;
                    } else {
                        for i in opening {
                            if (ret == i) {
                                finish += 1us;
                                break {}
                            }
                        }
                    }
                }

                self._commentEnds:.insert (start, (self._wordCursor, self._cursor));
            }
        }
    }

    /**
     * Read the content to lex, and store the words
     */
    prv def readAll (mut self, dmut tzer : &Tokenizer) {
        let mut tzerCursor = 0us;
        let mut lineSeek = 0us;
        let mut line = 1u64;
        let mut col = 1u64;

        let dmut wordInfos = Vec!{(usize, bool, [c8], [[c8]])}::new ();
        let dmut words = Vec!{&Word}::new ();
        wordInfos:.reserve (self._content.len / 5us);
        words:.reserve (self._content.len / 5us);

        loop {
            let (len, isSkip, isComment, opening) = tzer:.next (self._content [tzerCursor .. $]);
            if (len == 0us) break {}

            let ret = self._content [tzerCursor  .. tzerCursor + len];
            wordInfos:.push ((len, isSkip, isComment, opening));
            words:.push (Word::new (ret, filename-> self._filename, fileContent-> self._content, line, col, tzerCursor, lineSeek));
            tzerCursor += len;

            if (ret [0us] == '\n'c8) {
                lineSeek = lineSeek + cast!usize (col);
                line += 1u64;
                col = 1u64;
            } else { col += len; }
        }

        wordInfos:.fit ();
        words:.fit ();

        self._wordInfos = wordInfos[];
        self._words = words[];
    }
    
    /***
     * ==================================================================================
     * ==================================================================================
     * =========================          MISCELLANEOUS        ==========================
     * ==================================================================================
     * ==================================================================================
     */
    
    impl Streamable;
    
    
}
