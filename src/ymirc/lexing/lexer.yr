mod ymirc::lexing::lexer;
    
import ymirc::lexing::word;
import ymirc::lexing::tokenizer;

import std::io;
import std::collection::vec;
import std::collection::map;
import std::collection::set; 

/**
 * The lexer is the class responsible of cutting a source code string into a list of tokens
 * Unlike simple tokenizer, the lexer has context information, and switch (allowing to ignore parts of the source code, or not depending of the context)
 */
pub class @final Lexer {

    /// The tokenizer that is able to cut a string into tokens
    let dmut _tzer : &Tokenizer;
    
    /// The name of the file that the lexer is reading
    let _filename : [c8];

    /// The content of the file, that is tokenized
    let _content : [c8];

    /// The list of comments { begin => end }
    let dmut _comments = HashMap!{[c8], [c8]}::new ();

    /// The list of tokens to skip
    let mut _skips : [[c8]] = [];//}::new ()

    /// Does the lexer has to skip comments
    let mut _doComments = true;

    /// The current line of the lexer
    let mut _line = 1u64;

    // The current column
    let mut _col = 1u64;

    /// The position of the cursor
    let mut _cursor = 0us;

    let mut _wordCursor = 0us;

    let mut _words : [(usize, bool, [c8], u64, u64, usize)] = [];
    
    /// The position of the (cursors, line, col, lineSeek) of the previous read words 
    let dmut _rewinders = Vec!{(usize, u64, u64, usize, usize)}::new ();

    /// The position of the cursor to the beginning of the current line
    let dmut _lineSeek = 0us;

    /// Set to true, when nothing is left to read (iif _cursor >= _content.len)
    let mut _eof : bool = false;

    /// The word returns when the lexer is eof
    let _eofWord : &Word;

    /**
     * Create a new lexer, ready to split content
     * @params: 
     *    - content: the content to split
     *    - tokens: the list of tokens that split the string, (cf. Tokenizer)
     *    - comments: the list of tokens that start a comment line (by default [])
     *    - skips: the list of tokens that will be omitted by the lexer when reading (by default [" ", "\n", "\t", "\r"])
     * @warning: if the skips and comments token are not in tokens, they are added, so they split the content 
     */
    pub self (filename : [c8], content : [c8], tokens: [[c8]] = [" "s8], comments : [([c8], [c8])] = [], skips: [[c8]] = [" "s8, "\n"s8, "\t"s8, "\r"s8])
        with _filename = filename,
        _tzer = Tokenizer::new (tokens-> tokens),
        _content = content, _eofWord = Word::eof (filename-> filename)
    {        
        self._rewinders:.push ((self._cursor, self._line, self._col, self._lineSeek, self._wordCursor));
        for i in comments {
            self._comments:.insert (i._0, i._1);
            self._tzer:.insert (i._0, isComment-> i._1);
        }

        for i in skips {
            self._tzer:.insert (i, isSkip-> true);
        }
        
        self._skips = skips;

        let mut cursor = 0us;
        let dmut words = Vec!{(usize, bool, [c8], u64, u64, usize)}::new ();
        let mut line = 1u64, mut col = 1u64, mut lineSeek = 0us;
        __pragma!trusted ({
            loop {
                let (len, isSkip, isComment) = self._tzer:.next (content [cursor .. $]);
                if (len != 0us) {
                    if (content [cursor .. cursor + len] == "\n"s8) {
                        lineSeek = lineSeek + cast!usize (col);
                        line += 1u64;
                        col = 1u64;
                    } else { col += len; }
                    words:.push ((len, isSkip, isComment, line, col, lineSeek));
                } else break {}
                cursor += len;
            }
        });
        
        self._words = words[];       
    }        

    /**
     * Read the next word in the lexer, and returns it, with the documentation read before it
     */
    pub def next (mut self)-> (&Word, [c8]) {
        if (self._eof) return (self._eofWord, ""s8);
        
        self._rewinders:.push ((self._cursor, self._line, self._col, self._lineSeek, self._wordCursor));
        let mut start_com = 0us;
        let mut end_com = 0us;
        return loop {            
            let (wd, wasSkip, isComment, line, col, lineSeek) = if (self._wordCursor < self._words.len) {
                self._words [self._wordCursor]
            } else { (0us, false, ""s8, 0u64, 0u64, 0us) }
            
            if (wd != 0us) {
                let ret = self._content [self._cursor .. self._cursor + wd];
                self._wordCursor += 1us;
                self._cursor += wd;
                let isSkip =  wasSkip && (self._skips.len != 0us);
                
                let (old_l, old_c) = (self._line, self._col);
                self._line = line;
                self._col = col;
                self._lineSeek = lineSeek;
                
                if (self._doComments) {                                       
                    if (isComment != ""s8) {
                        start_com = self._cursor - wd;
                        self:.gotoNextToken (isComment);
                        end_com = self._cursor;
                    } else {                   
                        if (!isSkip) {
                            return (Word::new (str-> ret, filename-> self._filename, fileContent-> self._content, old_l, old_c, self._cursor - wd, self._lineSeek), self._content [start_com .. end_com]);                    
                        }                        
                    }
                } else {
                    if (!isSkip) {
                        return (Word::new (str-> ret, filename-> self._filename, fileContent-> self._content, old_l, old_c, self._cursor - wd, self._lineSeek), ""s8);                    
                    }
                }
            } else {
                self._eof = true;
                break (self._eofWord, ""s8);
            }
        };
    } 
    
    /***
     * ============================================================================
     * ============================================================================
     * =========================          SETTERS        ==========================
     * ============================================================================
     * ============================================================================
     */

    /**
     * Tell to the lexer if it must skip the 'skips' or not
     * @info: 
     *   - by default the lexer skips them
     *   - This function is used to disable token skipping when reading string content for example
     */
    pub def doComments (mut self, d : bool) -> void {
        self._doComments = d;
    }

    /**
     * Set the list of skip tokens
     * @params:
     *  - skips: the list of token to skip
     */
    pub def setSkips (mut self, skips : [[c8]]) {            
        // self._skips:.clear ();
        
        // for i in skips {
        //     self._skips:.insert (i);
        // }
        self._skips = skips;
    }
    
    /**
     * Rewind to a previous location in the file
     * Each time the function next is called, the lexer saves the cursor position
     * This function rewind go to that cursor position, so if we rewind 10 times, we will get the last 10 next calls
     * @warning: 
     * ===============
     * when toggeling skips, and doComment, the rewind does not garantee, that the lexer will return at least nb tokens
     * ===============
     */
    pub def rewind (mut self, nb : u64 = 1u64) {
        if (self._eof) {
            self._rewinders:.pop ()?;
            self._eof = false;
        }

        {
            for _ in 0u64 .. nb {                
                let (x, y, z, w, h) = self._rewinders [self._rewinders.len () - 1us] ;
                self._cursor = x;
                self._line = y;
                self._col = z;
                self._lineSeek = w;
                self._wordCursor = h;
                self._rewinders:.pop ();
            }
        } catch { _ => {}}

        if (self._rewinders.len () == 0us) {
            self._rewinders:.push ((self._cursor, self._line, self._col, self._lineSeek, self._wordCursor));
        }
    }

    /**
     * Rewind to a previous location in the file
     * Each time the function next is called, the lexer saves the cursor position
     * This function rewind go to that cursor position, so if we rewind 10 times, we will get the last 10 next calls
     * @warning: 
     * ===============
     * when toggeling skips, and doComment, the rewind does not garantee, that the lexer will return at least nb tokens
     * ===============
     */
    pub def rewindTo (mut self, nb : u64) {
        if (self._eof) {
            self._rewinders:.pop ()?;
            self._eof = false;
        }

        {
            while cast!u64 (self._rewinders.len ()) > nb {
                let (x, y, z, w, h) = self._rewinders [self._rewinders.len () - 1us] ;
                self._cursor = x;
                self._line = y;
                self._col = z;
                self._lineSeek = w;
                self._wordCursor = h;
                self._rewinders:.pop ();            
            }
        } catch {
            _ => {}
        }

        if (self._rewinders.len () == 0us) {
            self._rewinders:.push ((self._cursor, self._line, self._col, self._lineSeek, self._wordCursor));
        }
    }


    pub def rewindToSeek (mut self, cursor : u64) {
        if (self._eof) {
            self._rewinders:.pop ()?;
            self._eof = false;
        }

        {
            loop {
                if (self._rewinders.len () == 0us) break {}            
                let (x, y, z, w, h) = self._rewinders [self._rewinders.len () - 1us] ;
                self._cursor = x;
                self._line = y;
                self._col = z;
                self._lineSeek = w;
                self._wordCursor = h;
                self._rewinders:.pop ();
                
                if (x <= cursor) break {}
            }
        } catch {
            _ => {}
        }

        if (self._rewinders.len () == 0us) {
            self._rewinders:.push ((self._cursor, self._line, self._col, self._lineSeek, self._wordCursor));
        }
    }

    /***
     * ============================================================================
     * ============================================================================
     * =========================          GETTERS        ==========================
     * ============================================================================
     * ============================================================================
     */
    
    /**
     * @returns: the counter of previous "self:.next" calls
     * @info: this information can be usefull to go back rapidely
     * @example: 
     * =================
     * let dmut lex : &Lexer = ...
     * let read_Nb : u64 = ...
     * let counter = lex.getCounter ();
     * for i in 0 .. read_Nb {
     *     println (lex:.next ()._0);
     * }
     * lex:.rewind (nb-> lex.getCounter () - counter); // go back of number of valid read done
     * // so the lexer will be reset, as if the for loop never executed
     * =================
     */
    pub def getCounter (self)-> u64 {
        cast!u64 (self._rewinders.len ())
    }

    

    /***
     * ============================================================================
     * ============================================================================
     * =========================          PRIVATE        ==========================
     * ============================================================================
     * ============================================================================
     */
    
    /**
     * Move the cursor (and counters) to the next token == end
     */
    prv def gotoNextToken (mut self, end : [c8])-> void {
        loop {
            let (wd, _, _, line, col, lineSeek) = if (self._wordCursor < self._words.len) {
                self._words [self._wordCursor]
            } else { (0us, false, ""s8, 0u64, 0u64, 0us) }

            if wd != 0u64 {
                let ret = self._content [self._cursor .. self._cursor + wd];
                self._wordCursor += 1us;
                self._cursor += wd;
                self._line = line;
                self._col = col;
                self._lineSeek = lineSeek;

                if (ret == end) break {}
            } else {
                break {}
            }
        }
    }

    /***
     * ==================================================================================
     * ==================================================================================
     * =========================          MISCELLANEOUS        ==========================
     * ==================================================================================
     * ==================================================================================
     */
    
    impl Streamable;
    
    
}



