/*
 * @Package: ymirc        
 * @Module: ymirc::lexing::tokenizer
 * @File: ymirc/lexing/tokenizer.yr
 *
 * @Purpose:
 *   Declare the SrcTokenizer record to help splitting the src content
 *   into tokens, and store some utils to check string information, comment
 *   information, isToken, isKeyword, etc. 
 *
 * @Author(s):
 *   - Emile Cadorel ecadorel@gmail.com
 *
 * @Created (YYYY-MM-DD): 2026-02-08 
 *
 * @Copyright (C) 2021â€“2026 GNU-Ymir
 * 
 * ```text
 * This file is part of the Ymir language project.
 *
 * Ymir is free software: you can redistribute it and/or modify it
 * under the terms of the GNU General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * Ymir is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 * You should have received a copy of the GNU General Public License
 * along with Ymir.  If not, see <https://www.gnu.org/licenses/>.
 * ```
 */

in tokenizer;

mod ::implem;
mod ::node;
mod ::slice;

use ymirc::lexing::{keys, tokens};

/**
 * The source tokenizer is immutable element once initialized, but
 * initialization takes time and memory, so initializing it only one time is
 * enough
 * 
 * */
pub lazy __SRC_TOKENIZER__ = SrcTokenizer ();


pub def Tokenizer : implem::Tokenizer;
pub def Slice     : slice::Slice;

/**
 * A tokenizer utils that contains useful informations for the lexer
 * */
pub record SrcTokenizer {

    /*! Private fields */
    prv {        
        // The tokenizer
        let mut _tzer: Tokenizer;

        // end of comment and strings to manage nested cuts
        let mut _stringComEnds: [[c8] => mut [[c8] => mut ()]] = copy [];

        // the list of starters of strings. Tokenizer does not manage strings
        // tagging, so we will use it's comment tagging and check wether it's a
        // string or a comment.
        // content: open => (close, multiline)
        let mut _stringInfos: [[c8] => mut ([c8], bool, [[c8]], bool)] = copy [];

        // The informations about comments to decide what to do with them
        // content: open => (close, multiline, doc)
        let mut _commInfos: [[c8] => mut ([c8], bool, bool)] = copy [];

        // The set of keywords
        let mut _keywords: [[c8] => mut ()] = copy [];

        // The set of suffixes for float values
        let mut _floatSuffixes: [[c8] => mut ()] = copy [];

        // The set of suffixes for int values
        let mut _intSuffixes: [[c8] => mut ()] = copy [];
    }

    /*!
     * ====================================================================================================
     * ====================================================================================================
     * ======================================          CTOR          ======================================
     * ====================================================================================================
     * ====================================================================================================
     */
    
    pub self ()        
        with _tzer = Tokenizer (copy Tokens::__members__)        
    {
        self:.configure ();
    }

    /*!
     * ====================================================================================================
     * ====================================================================================================
     * ===================================          SPLITTERS          ====================================
     * ====================================================================================================
     * ====================================================================================================
     */

    /**
     * Find the next token in `str`
     *
     * @returns: the splitted token
     * */
    pub fn next (self, str: [c8])-> Slice {
        let (len, isToken, isSkip, isComment, isString) = self._tzer.next (str);
        if len == 0 // Empty split, EOF
            return Slice ();

        let mut split = Slice ();
        split.tok = str [0 .. len];
        split.isToken = isToken;
        split.isSkip = isSkip;
        split.isString = isString;
        split.isComment = isComment;

        if !split.isToken {
            split.isKeyword = (split.tok in self._keywords);
        }

        split        
    }
        
    /*!
     * ====================================================================================================
     * ====================================================================================================
     * ====================================          GETTERS          =====================================
     * ====================================================================================================
     * ====================================================================================================
     */
    
    /**
     * Find the string info from the opening token
     * 
     * @returns:
     *    - .0: the closing token
     *    - .1: true iif multiline
     *    - .2: the list of suffixes for that string opener
     * */
    pub fn stringInfo (self, tok: [c8])-> ([c8], bool, [[c8]], bool) {
        if let Ok (x) = self._stringInfos [tok] {
            x
        } else {
            ("", false, [], false)
        }
    }    
    
    /**
     * Find the comment info from the opening token
     * 
     * @returns:
     *    - .0: the closing token
     *    - .1: true iif multiline
     *    - .2: true iif keep in documentation
     * */
    pub fn commentInfo (self, tok: [c8])-> ([c8], bool, bool) {
        if let Ok (x) = self._commInfos [tok] {
            x
        } else {
            ("", false, false)
        }
    }

    /**
     * @returns: the list of tokens that can open a nest comment/string closing with `closing`
     * */
    pub fn openList (self, closing: [c8])-> [[c8] => ()] {
        if let Ok (x) = self._stringComEnds [closing] {
            x
        } else {
            copy []
        }
    }

    /**
     * @returns: true if `tok` is a float suffix
     * */
    pub fn isFloatSuffix (self, tok: [c8])-> bool {
        tok in self._floatSuffixes
    }
    
    /**
     * @returns: true if `tok` is a int suffix
     * */
    pub fn isIntSuffix (self, tok: [c8])-> bool {
        tok in self._intSuffixes
    }

    /*!
     * ====================================================================================================
     * ====================================================================================================
     * =================================          CONFIGURATION          ==================================
     * ====================================================================================================
     * ====================================================================================================
     */

    /**
     * Configure the tokenizer with the keywords and tokens
     * */
    fn configure (mut self) {
        
        // Flag the comment tokens
        for i in CommentTokens::__members__ {
            self._tzer:.insert (i._0, isComment-> true);

            // insert the list of tokens that can start a comment with the same end
            // For nesting checks
            if let Ok (dmut x) = alias self._stringComEnds [i._1] { 
                x [i._0] = ();
                self._stringComEnds [i._1] = alias x;
            } else {
                self._stringComEnds [i._1] = copy [i._0 => ()];
            }

            // Insert the com info
            self._commInfos [i._0] = (i._1, i._2, i._3);
        }

        // Flag the string tokens
        for i in StringTokens::__members__ {
            self._tzer:.insert (i._0, isString-> true);

            // insert the list of tokens that can start a string with the same end
            // For nesting checks
            if let Ok (dmut x) = alias self._stringComEnds [i._1] { 
                x [i._0] = ();
                self._stringComEnds [i._1] = alias x;
            } else {
                self._stringComEnds [i._1] = copy [i._0 => ()];
            }
            
            // Insert the string start to make a different management than comments
            let lst = if i._0 == Tokens::DQUOTE {
                copy StringSuffixes::__members__
            } else if i._0 == Tokens::SQUOTE {
                copy CharSuffixes::__members__
            } else { [] };

            let ident = (i._0 == Tokens::BACK_QUOTE);
            self._stringInfos [i._0] = (i._1, i._2, lst, ident);
        }

        // Insert of flags the skips tokens
        for i in SkipTokens::__members__ {
            self._tzer:.insert (i, isSkip-> true);
        }

        // Insert the keywords in the set
        for k in ForbiddenKeys::__members__ {
            self._keywords [k] = ();
        }

        for k in FloatSuffixes::__members__ {
            self._floatSuffixes [k] = ();
        }

        for k in FixedSuffixes::__members__ {
            self._intSuffixes [k] = ();
        }
        
    }
}
