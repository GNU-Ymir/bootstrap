mod ymirc::lexing::tokenizer;

import core::object;
import core::array;
import core::typeinfo;
import core::exception;

import std::collection::map;
import std::collection::vec;
import std::io;
import std::algorithm::comparison;

/**
 * A tokenizer is an enhanced string splitter, that splits strings using tokens instead of just chars
 * Tokenizer are really usefull for grammar visitor, and can be associated with Lexers pretty easily
 * @example: 
 * ============
 * // using a tokenizer, tokens can be multiple letter long, and there can be collision between tokens
 * // For example, the token '=' and '=>' won't be a problem for the tokenizer
 * let dmut tzer = Tokenizer::new (tokens-> ["("s8, ")"s8, "=>"s8, ","s8, "="s8, "+"s8, "*"s8]);
 * // set a skip token
 * tzer:.insert (" "s8, isSkip-> true); 
 *
 * // insert a comment token
 * tzer:.insert ("#"s8, isComment-> "#"s8);
 *
 * let mut cursor = 0u64;
 * let str = "(x, y) => # this is a comment # x + y * 2"s8;
 * loop {
 *    let (len, isSkip, isComment) = tzer.next (str [cursor .. $]);
 *    if len != 0u64 {
 *        println (format ("%(y) -> %(b), %(r)"s8, str [cursor .. cursor + len], isSkip, isComment));
 *    } else break {}
 * }
 * ============
 */
pub class @final Tokenizer {

    let dmut _heads : [&internal::Node] = [];

    let dmut _keyHeads : [c8] = [];
    
    /**
     * Create a new tokenizer, with a set of tokens
     * @params: 
     *   - tokens: the list of token that will split the string
     * @example: 
     * ============
     * let dmut tzer = Tokenizer::new (tokens-> ["(", ")", "=>", ":", "<", ">", ",", " "]);
     * let str = "(x, y) => x > y";
     * let lst = tzer.tokenize (str);
     * assert (lst == ["(", "x", ",", " ", "y", ")", " ", "=>", " ", "x", " ", ">", " ", "y"]); 
     * ============
     */
    pub self (tokens: [[c8]] = []) {
        for i in tokens {
            self:.insert (i, isSkip-> false, isComment-> ""s8);
        }
    }
    
    /**
     * Insert a new token in the tokenizer
     * @params: 
     *    - token: the token to insert
     * @example: 
     * ================
     * let dmut tzer = Tokenizer::new ();
     * tzer:.insert ("+");
     * tzer:.insert ("+=");
     * tzer:.insert (" ");
     * let lst = tzer.tokenize ("x += y");
     * assert (lst == ["x", " ", "+=", " ", "y"]);
     * ================
     */
    pub def insert (mut self, token : [c8], isSkip : bool = false, isComment : [c8] = ""s8) {
        if (token.len != 0us) {            
            for i in 0us .. self._keyHeads.len {
                if self._keyHeads [i] == token [0] {
                    (self._heads[i]):.insert (token [1us .. $], isSkip-> isSkip, isComment-> isComment);
                    return {}
                }
            }

            self._keyHeads = alias (self._keyHeads ~ [token [0]]);
            let dmut n = internal::Node::new (token [0], isSkip-> false, isComment-> ""s8);
            n:.insert (token [1us .. $], isSkip-> isSkip, isComment-> isComment);
            self._heads = alias (self._heads ~ [alias n]);
            self:.sort ();
        }        
    }    
    
    /**
     * @returns: 
     *   - the length of the next token inside the str
     *   - true, if the token is a skip token false otherwise
     *   - if the token is a comment starter, it returns the comment ender, ""s8 otherwise
     * @example: 
     * ============
     * let dmut tzer = Tokenizer::new (["+", " "]);
     * let mut str = "fst + scd";
     * let mut len = tzer.next (str)._0;
     * assert (len == 3u64); // "fst"
     * 
     * str = str [len .. $];     
     * len = tzer.next (str)._0;
     * assert (len == 1u64); // " "
     *
     * str = str [len .. $];     
     * len = tzer.next (str)._0;
     * assert (len == 1u64); // "+"
     *
     * str = str [len .. $];     
     * len = tzer.next (str)._0;
     * assert (len == 1u64); // " "
     *
     * str = str [len .. $];     
     * len = tzer.next (str)._0;
     * assert (len == 3u64); // "scd" 
     *
     * str = str [len .. $];     
     * len = tzer.next (str)._0;
     * assert (len._0 == 0u64); 
     * ============
     */
    pub def @final next (mut self, str : [c8])-> (usize, bool, [c8]) {
        for s in 0us .. str.len {            
            let i = self.find (str [s]);            
            if (i != self._keyHeads.len) {
                if (s != 0us) return (s, false, ""s8);
                let (len, isSkip, isComment) = (self._heads [i]):.len (str [1us .. $]); // get the length of the token
                // if the len is 0, then it is not really a token, it just start like one
                if (len != 0us) {
                    if (s == 0us) {
                        return (len, isSkip, isComment); // it is totally a token, we return its length
                    } else {
                        // it is a token, but there is something before it, so we return the len of the thing before it
                        return (s, false, ""s8); 
                    }
                }
            }            
        }
        
        // No token in the str, return the len of the str
        return (str.len, false, ""s8);
    }    

    
    def swap (mut self, i : usize, j : usize) {
        let dmut aux = alias self._heads [i];
        let aux_k = self._keyHeads [i];
        
        self._heads [i] = alias self._heads [j];
        self._heads [j] = alias aux;

        self._keyHeads [i] = self._keyHeads [j];
        self._keyHeads [j] = aux_k;
    }

    def sort (mut self) {
        if (self._keyHeads.len > 1us) {
            for i in 1us .. self._keyHeads.len {
                for j in 0us .. (self._keyHeads.len - i) {
                    if (self._keyHeads [j + 1us] < self._keyHeads [j]) {
                        self:.swap (j + 1us, j);
                    }
                    
                }                
            }
        }
    } 

    def find (self, s : c8) -> usize {
        if (self._keyHeads.len == 0us) return 0us;
        
        let mut begin = 0us;
        let mut end = self._keyHeads.len - 1us;
        
        while begin <= end {
            let center = (begin + end) / 2us;
            if self._keyHeads [center] == s {
                return center;
            } else {
                if s > self._keyHeads [center] {
                    begin = center + 1us;
                } else {
                    end = center - 1us;
                }
            }            
        }
        self._keyHeads.len
    } 
    
    impl Streamable;
    
}

mod internal {

    /**
     * A node of a tokenizer, that stores information about tokens
     */
    pub class @final Node {

        // The current value of the node
        let _key : c8; 

        // Can terminate a token? or is part of bigger tokens
        let mut _isToken : bool = false;

        // The list of possible continuation of the token
        let dmut _heads : [dmut &Node] = [];

        /// The list of keys 
        let dmut _keyHeads : [c8] = [];

        let mut _isSkip : bool;

        let mut _isComment : [c8];

        let dmut _frequency : [usize] = [];
        
        /**
         * Construct a new Token node
         * @params: 
         *   - key: the value of the node
         *   - isToken: can terminate a token 
         *   - heads: the list of possible continuation
         */
        pub self (key : c8, isToken : bool = false, isSkip : bool, isComment : [c8]) with _key = key, _isToken = isToken, _isSkip = isSkip, _isComment = isComment
        {}
        
        /**
         * Insert sub tokens accepted tokens
         * @params: 
         *     - str: the rest to read to create a valid token
         * @example: 
         * ==============
         * // let say that "[+]" is a token, but "[" is not, nor is "[+"
         * let dmut node = Node::new ('['); 
         * node:.insert ("+]"); 
         * println (node); // [:false, +:false, ]:true 
         * // In that configuration the only token that will be accepted is "[+]"
         * assert (node.len ("[+]") == 3); // accepted
         * assert (node.len ("[") == 0u64); // not accepted
         * assert (node.len ("[+") == 0u64); // not accepted
         * 
         * // Now we want to accept "[-]"
         * node = node.insert ("-]");
         * // and simply "["
         * node = node.insert (""); 
         * println (node); // [:true, 
         *                 //     +:false, ]:true 
         *                 //     -: false, ]:true
         * 
         * assert (node.len ("[+]") == 3); // still accepted
         * assert (node.len ("[") == 1u64); // accepted this time
         * assert (node.len ("[+") == 1u64); // accept only the '['
         * assert (node.len ("[-]") == 3); // accepted
         * assert (node.len ("[-") == 1u64); // accept only the '['
         * ==============
         */
        pub def insert (mut self, str : [c8], isSkip : bool, isComment : [c8]) {
            if (str.len == 0u64) {
                self._isToken = true;
                self._isSkip = isSkip;
                self._isComment = isComment;
                return {}
            }
            
            for i in 0us .. self._keyHeads.len {
                if (self._keyHeads [i] == str [0]) {
                    (self._heads[i]):.insert (str [1us .. $], isSkip, isComment);
                    return {}
                }
            }

            self._keyHeads = alias (self._keyHeads ~ [str[0]]);
            let dmut node = Node::new (str [0], false, ""s8);
            node:.insert (str [1us .. $], isSkip, isComment);
            self._heads = alias (self._heads ~ [alias node]);
        }

        

        /**
         * @returns: the length of the token at the beginning of the string content
         * @example: 
         * =================
         * let mut node = Node::new ('+', isToken-> true);
         * node = node.insert ("=");
         * // Our grammar accept the tokens, "+" and "+="
         * assert (node.len ("+")._0 == 1u64); // "+" are accepted
         * assert (node.len ("+=")._0 == 2u64); // "+=" are accepted
         * assert (node.len (" +=")._0 == 0u64); // " +=" are not accepted
         * assert (node.len ("+ and some rest")._0 == 1u64); // " +" are accepted
         * =================
         */
        pub def @final len (mut self, content : [c8])-> (usize, bool, [c8]) {
            if (content.len == 0us) {
                if (self._isToken)
                    return (1us, self._isSkip, self._isComment);
                else return (0us, false, ""s8);
            }
            
            for i in 0us .. self._keyHeads.len {
                if (self._keyHeads [i] == content [0]) {
                    let (sub_len, isSkip, isComment) = self._heads [i]:.len (content [1us .. $]);
                    if (sub_len != 0us) {
                        return (1us + sub_len, isSkip, isComment);
                    }
                }
            }

            if (self._isToken)
                return (1us, self._isSkip, self._isComment);
            return (0us, false, ""s8);
        }
        
        /**
         * @returns: the key of the node
         */
        def key (self) -> c8 {
            self._key
        }

        /**
         * @returns: true, if this token is a skip token
         */
        def isSkip (self)-> bool {
            self._isSkip
        }

        /**
         * @returns: a closing token, is this token is a stater of a comment, ""s8 otherwise
         */
        def isComment (self)-> [c8] {
            self._isComment
        }                


        impl Streamable;
    }

}
